# Einführung

In diesem Lab werden wir den stochastischen Gradientenabstieg (SGD) untersuchen, ein leistungsstarkes Optimierungsverfahren, das in der Maschinellen Lernen häufig zur Lösung von großskaligen und dünn besetzten Problemen verwendet wird. Wir werden lernen, wie man die Klassen SGDClassifier und SGDRegressor aus der scikit-learn-Bibliothek verwendet, um lineare Klassifizierer und Regressoren zu trainieren.

## VM-Tipps

Nachdem die VM gestartet ist, klicken Sie in der oberen linken Ecke, um zur Registerkarte **Notebook** zu wechseln und Jupyter Notebook für die Übung zu nutzen.

Manchmal müssen Sie einige Sekunden warten, bis Jupyter Notebook vollständig geladen ist. Die Validierung von Vorgängen kann aufgrund der Einschränkungen von Jupyter Notebook nicht automatisiert werden.

Wenn Sie bei der Lernphase Probleme haben, können Sie Labby gerne fragen. Geben Sie nach der Sitzung Feedback ab, und wir werden das Problem für Sie prompt beheben.

<div class="text-xs text-gray-500 dark:text-gray-400 mt-4 border-t border-l-2 border-gray-300 dark:border-gray-600 pt-2 pl-4">
Dies ist ein Guided Lab, das schrittweise Anweisungen bietet, um Ihnen beim Lernen und Üben zu helfen. Befolgen Sie die Anweisungen sorgfältig, um jeden Schritt abzuschließen und praktische Erfahrungen zu sammeln. Historische Daten zeigen, dass dies ein Labor der Stufe <span class="text-green-600 dark:text-green-400">Anfänger</span> mit einer Abschlussquote von <span class="text-green-600 dark:text-green-400">92%</span> ist. Es hat eine positive Bewertungsrate von <span class="text-primary-600 dark:text-primary-400">86%</span> von den Lernenden erhalten.
</div>
