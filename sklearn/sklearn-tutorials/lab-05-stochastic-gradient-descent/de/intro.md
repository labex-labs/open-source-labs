# Einführung

In diesem Lab werden wir den stochastischen Gradientenabstieg (SGD) untersuchen, ein leistungsstarkes Optimierungsverfahren, das in der Maschinellen Lernen häufig zur Lösung von großskaligen und dünn besetzten Problemen verwendet wird. Wir werden lernen, wie man die Klassen SGDClassifier und SGDRegressor aus der scikit-learn-Bibliothek verwendet, um lineare Klassifizierer und Regressoren zu trainieren.

## VM-Tipps

Nachdem die VM gestartet ist, klicken Sie in der oberen linken Ecke, um zur Registerkarte **Notebook** zu wechseln und Jupyter Notebook für die Übung zu nutzen.

Manchmal müssen Sie einige Sekunden warten, bis Jupyter Notebook vollständig geladen ist. Die Validierung von Vorgängen kann aufgrund der Einschränkungen von Jupyter Notebook nicht automatisiert werden.

Wenn Sie bei der Lernphase Probleme haben, können Sie Labby gerne fragen. Geben Sie nach der Sitzung Feedback ab, und wir werden das Problem für Sie prompt beheben.
