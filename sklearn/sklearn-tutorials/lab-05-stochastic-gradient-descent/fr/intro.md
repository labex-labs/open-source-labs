# Introduction

Dans ce laboratoire, nous explorerons la descente de gradient stochastique (SGD), qui est un puissant algorithme d'optimisation couramment utilisé en apprentissage automatique pour résoudre des problèmes à grande échelle et creux. Nous apprendrons à utiliser les classes SGDClassifier et SGDRegressor de la bibliothèque scikit-learn pour entraîner des classifieurs linéaires et des régresseurs.

## Conseils sur la machine virtuelle

Une fois le démarrage de la machine virtuelle terminé, cliquez dans le coin supérieur gauche pour basculer vers l'onglet **Notebook** pour accéder à Jupyter Notebook pour la pratique.

Parfois, vous devrez peut-être attendre quelques secondes pour que Jupyter Notebook ait fini de charger. La validation des opérations ne peut pas être automatisée en raison des limitations de Jupyter Notebook.

Si vous rencontrez des problèmes pendant l'apprentissage, n'hésitez pas à demander à Labby. Donnez des commentaires après la session, et nous réglerons rapidement le problème pour vous.
