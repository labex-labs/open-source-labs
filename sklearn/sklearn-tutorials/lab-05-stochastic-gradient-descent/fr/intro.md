# Introduction

Dans ce laboratoire, nous explorerons la descente de gradient stochastique (SGD), qui est un puissant algorithme d'optimisation couramment utilisé en apprentissage automatique pour résoudre des problèmes à grande échelle et creux. Nous apprendrons à utiliser les classes SGDClassifier et SGDRegressor de la bibliothèque scikit-learn pour entraîner des classifieurs linéaires et des régresseurs.

## Conseils sur la machine virtuelle

Une fois le démarrage de la machine virtuelle terminé, cliquez dans le coin supérieur gauche pour basculer vers l'onglet **Notebook** pour accéder à Jupyter Notebook pour la pratique.

Parfois, vous devrez peut-être attendre quelques secondes pour que Jupyter Notebook ait fini de charger. La validation des opérations ne peut pas être automatisée en raison des limitations de Jupyter Notebook.

Si vous rencontrez des problèmes pendant l'apprentissage, n'hésitez pas à demander à Labby. Donnez des commentaires après la session, et nous réglerons rapidement le problème pour vous.

<div class="text-xs text-gray-500 dark:text-gray-400 mt-4 border-t border-l-2 border-gray-300 dark:border-gray-600 pt-2 pl-4">
Ceci est un Guided Lab, qui fournit des instructions étape par étape pour vous aider à apprendre et à pratiquer. Suivez attentivement les instructions pour compléter chaque étape et acquérir une expérience pratique. Les données historiques montrent que c'est un laboratoire de niveau <span class="text-green-600 dark:text-green-400">débutant</span> avec un taux de réussite de <span class="text-green-600 dark:text-green-400">92%</span>. Il a reçu un taux d'avis positifs de <span class="text-primary-600 dark:text-primary-400">86%</span> de la part des apprenants.
</div>
