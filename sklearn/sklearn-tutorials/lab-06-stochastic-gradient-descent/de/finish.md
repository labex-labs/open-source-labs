# Zusammenfassung

In diesem Lab haben wir gelernt, wie man den stochastischen Gradientenabstieg (Stochastic Gradient Descent, SGD) mit scikit-learn implementiert. Wir haben den Iris-Datensatz (iris dataset) geladen, die Daten vorverarbeitet, sie in Trainings- und Testsätze aufgeteilt, einen SGD-Klassifikator (SGD classifier) trainiert, Vorhersagen getroffen und die Leistung des Klassifikators bewertet. SGD ist ein leistungsstarkes Optimierungsalgorithmus, der in der Maschinellen Lernens (Machine Learning) für groß angelegte Probleme weit verbreitet ist.
