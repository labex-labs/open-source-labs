# Введение

Стохастический градиентный спуск (Stochastic Gradient Descent, SGD) — популярный алгоритм оптимизации, используемый в машинном обучении. Это вариант алгоритма градиентного спуска, который на каждой итерации использует случайно выбранное подмножество обучающих данных. Это делает его вычислительно эффективным и подходящим для обработки больших наборов данных. В этом практическом занятии (лабораторной работе) мы рассмотрим шаги по реализации SGD на Python с использованием библиотеки scikit-learn.

## Советы по виртуальной машине (VM)

После запуска виртуальной машины нажмите в левом верхнем углу, чтобы переключиться на вкладку **Notebook** и получить доступ к Jupyter Notebook для практики.

Иногда вам может потребоваться подождать несколько секунд, пока Jupyter Notebook загрузится. Валидация операций не может быть автоматизирована из-за ограничений Jupyter Notebook.

Если у вас возникнут проблемы во время обучения, не стесняйтесь обращаться к Labby. Оставьте отзыв после занятия, и мы оперативно решим проблему для вас.
