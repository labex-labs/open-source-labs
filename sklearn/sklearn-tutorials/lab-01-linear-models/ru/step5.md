# Stochastic Gradient Descent (SGD)

Stochastic Gradient Descent (SGD) - это простой, но эффективный подход к обучению линейных моделей. Особенно полезен, когда количество примеров и признаков очень велико. SGD обновляет параметры модели с использованием небольшой подмножества тренировочных данных на каждой итерации, что делает его подходящим для онлайн-обучения и обучения за пределами ядра.

Построим модель логистической регрессии с использованием SGD.

```python
clf = linear_model.SGDClassifier(loss="log_loss", max_iter=1000)
clf.fit(X, y)

print(clf.coef_)
```

- Создаем экземпляр `SGDClassifier` с параметром `loss`, установленным на "log_loss", для выполнения логистической регрессии.
- Используем метод `fit`, чтобы обучить модель на тренировочных данных.
- Выводим коэффициенты модели логистической регрессии, полученной с использованием SGD.
