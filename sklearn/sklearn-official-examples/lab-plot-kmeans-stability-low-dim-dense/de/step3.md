# Quantitative Evaluation of Initialization Methods

Wir werden die Fähigkeit von K-Means-Initialisierungstrategien zur Herstellung einer robusten Konvergenz des Algorithmus evaluieren. Wir werden die relative Standardabweichung der Trägheit der Clustering berechnen, die die Summe der quadrierten Abstände zum nächsten Clusterzentrum ist. Das erste Diagramm zeigt die beste erreichte Trägheit für jede Kombination des Modells (`KMeans` oder `MiniBatchKMeans`) und der Init-Methode (`init="random"` oder `init="k-means++"`) für zunehmende Werte des `n_init`-Parameters, der die Anzahl der Initialisierungen steuert.

```python
n_runs = 5
n_init_range = np.array([1, 5, 10, 15, 20])

plt.figure()
plots = []
legends = []

cases = [
    (KMeans, "k-means++", {}, "^-"),
    (KMeans, "random", {}, "o-"),
    (MiniBatchKMeans, "k-means++", {"max_no_improvement": 3}, "x-"),
    (MiniBatchKMeans, "random", {"max_no_improvement": 3, "init_size": 500}, "d-"),
]

for factory, init, params, format in cases:
    print("Evaluation of %s with %s init" % (factory.__name__, init))
    inertia = np.empty((len(n_init_range), n_runs))

    for run_id in range(n_runs):
        X, y = make_data(run_id, n_samples_per_center, grid_size, scale)
        for i, n_init in enumerate(n_init_range):
            km = factory(
                n_clusters=n_clusters,
                init=init,
                random_state=run_id,
                n_init=n_init,
                **params,
            ).fit(X)
            inertia[i, run_id] = km.inertia_
    p = plt.errorbar(
        n_init_range, inertia.mean(axis=1), inertia.std(axis=1), fmt=format
    )
    plots.append(p[0])
    legends.append("%s with %s init" % (factory.__name__, init))

plt.xlabel("n_init")
plt.ylabel("inertia")
plt.legend(plots, legends)
plt.title("Mean inertia for various k-means init across %d runs" % n_runs)
```
