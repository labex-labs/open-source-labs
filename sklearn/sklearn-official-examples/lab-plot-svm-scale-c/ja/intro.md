# はじめに

この実験では、サポートベクターマシン (SVM) を使った分類において正則化パラメータをスケーリングする効果を示します。SVM 分類では、次の方程式のリスク最小化に興味があります。

```math
C \sum_{i=1, n} \mathcal{L} (f(x_i), y_i) + \Omega (w)
```

ここで：

- `C` は正則化の量を設定するために使用されます
- `L` はサンプルとモデルパラメータの損失関数です
- `Ω` はモデルパラメータのペナルティ関数です

## VM のヒント

VM の起動が完了したら、左上隅をクリックして **ノートブック** タブに切り替えて、Jupyter Notebook を使った練習にアクセスします。

時々、Jupyter Notebook が読み込み終了するまで数秒待つ必要があります。Jupyter Notebook の制限により、操作の検証を自動化することはできません。

学習中に問題に直面した場合は、Labby にお問い合わせください。セッション後にフィードバックを提供してください。すぐに問題を解決いたします。
