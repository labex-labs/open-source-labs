# Einführung

Beim maschinellen Lernen sind Hyperparameter Parameter, die nicht aus Daten gelernt werden, sondern vor dem Training festgelegt werden. Die Auswahl geeigneter Hyperparameter ist entscheidend für die Erreichung hoher Genauigkeiten in maschinellen Lernmodellen. Zwei gängige Methoden zur Hyperparameteroptimierung sind der zufällige Suchalgorithmus und das Gitterverfahren. In diesem Lab werden wir diese beiden Methoden zur Optimierung der Hyperparameter eines linearen Support Vector Machines (SVM) mit Stochastic Gradient Descent (SGD)-Training vergleichen.

## Tipps für die VM

Nachdem der Start der VM abgeschlossen ist, klicken Sie in der linken oberen Ecke, um zur Registerkarte **Notebook** zu wechseln und Jupyter Notebook für die Übung zu öffnen.

Manchmal müssen Sie einige Sekunden warten, bis Jupyter Notebook vollständig geladen ist. Die Validierung von Vorgängen kann aufgrund der Einschränkungen von Jupyter Notebook nicht automatisiert werden.

Wenn Sie bei der Lernphase Probleme haben, können Sie Labby gerne fragen. Geben Sie nach der Sitzung Feedback, und wir werden das Problem für Sie prompt beheben.
