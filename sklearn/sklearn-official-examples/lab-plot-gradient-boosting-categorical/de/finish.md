# Zusammenfassung

In diesem Lab haben wir vier verschiedene Pipelines zur Behandlung von kategorischen Merkmalen in Gradient-Boosting-Schätzern mithilfe des Ames Housing-Datensatzes verglichen. Wir haben festgestellt, dass das Entfernen von kategorischen Merkmalen zu einer schlechteren Vorhersageleistung führt und dass die drei Modelle, die kategorische Merkmale verwendeten, vergleichbare Fehlerraten hatten. Das One-Hot-Codieren der kategorischen Merkmale war bei weitem die langsamste Methode, während das Behandeln der kategorischen Merkmale als ordinalwerte und die Verwendung der nativen Kategorienunterstützung des HistGradientBoostingRegressor-Schätzers ähnliche Anpassungszeiten hatten. Wenn die Gesamtzahl der Aufteilungen begrenzt war, performierte die Strategie der nativen Kategorienunterstützung am besten.
