# Zusammenfassung

In diesem Lab haben wir die Early-Stopping-Strategie untersucht, um die Konvergenz bei der Verwendung des Stochastic Gradient Descent zur Minimierung einer Verlustfunktion anhand eines Validierungsscores zu überwachen. Wir haben das `SGDClassifier`-Modell aus scikit-learn und den MNIST-Datensatz verwendet, um zu veranschaulichen, wie Early Stopping verwendet werden kann, um fast die gleiche Genauigkeit wie ein Modell ohne Early Stopping zu erreichen und die Trainingszeit erheblich zu reduzieren. Wir haben drei verschiedene Stoppkriterien definiert: Kein Stoppkriterium, Trainingsverlust und Validierungsscore, und eine Schleife verwendet, um den Schätzer unter Verwendung jedes Stoppkriteriums zu trainieren und zu bewerten. Anschließend haben wir die Ergebnisse mit unterschiedlichen Linienstilen für jeden Schätzer und jedes Stoppkriterium geplottet.
