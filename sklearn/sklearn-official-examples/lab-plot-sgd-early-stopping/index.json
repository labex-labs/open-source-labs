{
  "$schema": "https://cdn.jsdelivr.net/gh/labex-labs/schema/index.json",
  "type": "lab",
  "title": "Early Stopping of Stochastic Gradient Descent",
  "description": "Stochastic Gradient Descent is a popular optimization technique used for minimizing a loss function. The technique performs gradient descent step by step in a stochastic manner, i.e., by randomly selecting samples for each iteration. The method is efficient, especially for fitting linear models. However, convergence is not guaranteed at each iteration, and the loss function may not necessarily decrease at each iteration. In this case, monitoring the convergence on the loss function can be difficult. In this lab, we will explore the early stopping strategy, which is an approach for monitoring convergence on a validation score. We will use the SGDClassifier model from the scikit-learn library and the MNIST dataset to illustrate how early stopping can be used to achieve almost the same accuracy as compared to a model built without early stopping, and significantly reduce training time.",
  "meta": {
    "title": "Stochastic Gradient Descent | MNIST Dataset | Early Stopping",
    "description": "Explore Stochastic Gradient Descent optimization technique, use MNIST dataset, and learn about early stopping strategy to improve model training efficiency.",
    "keywords": "Stochastic Gradient Descent, MNIST Dataset, Early Stopping, Optimization Technique, Machine Learning"
  },
  "difficulty": "Beginner",
  "time": 20,
  "hidden": false,
  "fee_type": "free",
  "show_in_tutorial": true,
  "details": {
    "steps": [
      {
        "title": "Load the necessary libraries and MNIST dataset",
        "text": "en/step1.md",
        "verify": [
          {
            "name": "This step has no verification at the moment",
            "file": "verify1-1.sh",
            "hint": "This step has no verification at the moment"
          }
        ],
        "skills": [
          "ml/sklearn",
          "sklearn/datasets",
          "sklearn/exceptions",
          "sklearn/model_selection",
          "sklearn/utils"
        ]
      },
      {
        "title": "Define the estimator and the early stopping strategy",
        "text": "en/step2.md",
        "verify": [
          {
            "name": "This step has no verification at the moment",
            "file": "verify2-1.sh",
            "hint": "This step has no verification at the moment"
          }
        ],
        "skills": ["ml/sklearn"]
      },
      {
        "title": "Train and evaluate the estimator",
        "text": "en/step3.md",
        "verify": [
          {
            "name": "This step has no verification at the moment",
            "file": "verify3-1.sh",
            "hint": "This step has no verification at the moment"
          }
        ],
        "skills": ["ml/sklearn"]
      },
      {
        "title": "Plot the results",
        "text": "en/step4.md",
        "verify": [
          {
            "name": "This step has no verification at the moment",
            "file": "verify4-1.sh",
            "hint": "This step has no verification at the moment"
          }
        ],
        "skills": ["ml/sklearn"]
      }
    ],
    "intro": {
      "text": "en/intro.md",
      "title": "Introduction",
      "background": "setup.sh"
    },
    "finish": {
      "text": "en/finish.md",
      "title": "Summary"
    },
    "assets": {
      "host01": [
        {
          "file": "plot-sgd-early-stopping.ipynb",
          "target": "/home/labex/project",
          "chmod": "ugo+rwx"
        }
      ]
    }
  },
  "backend": {
    "imageid": "jupyter-ubuntu:2204"
  },
  "contributors": [],
  "license": {
    "name": "BSD 3-Clause",
    "url": "https://github.com/scikit-learn/scikit-learn/tree/main/LICENSE",
    "repo": "https://github.com/scikit-learn/scikit-learn"
  },
  "i18n": [
    {
      "lang": "zh",
      "title": "随机梯度下降的早停法",
      "description": "随机梯度下降是一种常用的优化技术，用于最小化损失函数。该技术以随机方式逐步执行梯度下降，即在每次迭代中随机选择样本。这种方法效率很高，尤其适用于拟合线性模型。然而，每次迭代并不能保证收敛，损失函数也不一定在每次迭代时都会减小。在这种情况下，监测损失函数的收敛情况可能会很困难。在本实验中，我们将探索早停策略，这是一种根据验证分数监测收敛的方法。我们将使用 scikit-learn 库中的 SGDClassifier 模型和 MNIST 数据集来说明与未使用早停构建的模型相比，早停如何能够实现几乎相同的准确率，并显著减少训练时间。",
      "meta": {
        "title": "随机梯度下降 | MNIST 数据集 | 早停法",
        "description": "探索随机梯度下降优化技术，使用 MNIST 数据集，并了解早停策略以提高模型训练效率。",
        "keywords": "随机梯度下降, MNIST 数据集, 早停法, 优化技术, 机器学习"
      },
      "details": {
        "steps": [
          {
            "title": "加载必要的库和 MNIST 数据集",
            "text": "zh/step1.md",
            "verify": [
              {
                "name": "此步骤目前没有验证",
                "file": "verify1-1.sh",
                "hint": "此步骤目前没有验证"
              }
            ]
          },
          {
            "title": "定义估计器和早停策略",
            "text": "zh/step2.md",
            "verify": [
              {
                "name": "此步骤目前没有验证",
                "file": "verify2-1.sh",
                "hint": "此步骤目前没有验证"
              }
            ]
          },
          {
            "title": "训练并评估估计器",
            "text": "zh/step3.md",
            "verify": [
              {
                "name": "此步骤目前没有验证",
                "file": "verify3-1.sh",
                "hint": "此步骤目前没有验证"
              }
            ]
          },
          {
            "title": "绘制结果",
            "text": "zh/step4.md",
            "verify": [
              {
                "name": "此步骤目前没有验证",
                "file": "verify4-1.sh",
                "hint": "此步骤目前没有验证"
              }
            ]
          }
        ],
        "intro": {
          "text": "zh/intro.md",
          "title": "介绍"
        },
        "finish": {
          "text": "zh/finish.md",
          "title": "总结"
        }
      }
    },
    {
      "lang": "es",
      "title": "Parada temprana del Descenso de Gradiente Estocástico",
      "description": "El Descenso de Gradiente Estocástico es una técnica de optimización popular utilizada para minimizar una función de pérdida. La técnica realiza el descenso de gradiente paso a paso de manera estocástica, es decir, seleccionando aleatoriamente muestras para cada iteración. El método es eficiente, especialmente para ajustar modelos lineales. Sin embargo, no está garantizada la convergencia en cada iteración, y la función de pérdida no necesariamente disminuye en cada iteración. En este caso, es difícil monitorear la convergencia en la función de pérdida. En este laboratorio, exploraremos la estrategia de parada temprana, que es un enfoque para monitorear la convergencia en una puntuación de validación. Utilizaremos el modelo SGDClassifier de la biblioteca scikit-learn y el conjunto de datos MNIST para ilustrar cómo la parada temprana se puede utilizar para alcanzar casi la misma precisión que un modelo construido sin parada temprana, y reducir significativamente el tiempo de entrenamiento.",
      "meta": {
        "title": "Descenso de Gradiente Estocástico | Conjunto de datos MNIST | Parada temprana",
        "description": "Explora la técnica de optimización Descenso de Gradiente Estocástico, utiliza el conjunto de datos MNIST y aprende sobre la estrategia de parada temprana para mejorar la eficiencia del entrenamiento del modelo.",
        "keywords": "Descenso de Gradiente Estocástico, Conjunto de datos MNIST, Parada temprana, Técnica de optimización, Aprendizaje automático"
      },
      "details": {
        "steps": [
          {
            "title": "Cargar las bibliotecas necesarias y el conjunto de datos MNIST",
            "text": "es/step1.md",
            "verify": [
              {
                "name": "Este paso no tiene verificaciones en este momento",
                "file": "verify1-1.sh",
                "hint": "Este paso no tiene verificaciones en este momento"
              }
            ]
          },
          {
            "title": "Definir el estimador y la estrategia de parada temprana",
            "text": "es/step2.md",
            "verify": [
              {
                "name": "Este paso no tiene verificaciones en este momento",
                "file": "verify2-1.sh",
                "hint": "Este paso no tiene verificaciones en este momento"
              }
            ]
          },
          {
            "title": "Entrenar y evaluar el estimador",
            "text": "es/step3.md",
            "verify": [
              {
                "name": "Este paso no tiene verificaciones en este momento",
                "file": "verify3-1.sh",
                "hint": "Este paso no tiene verificaciones en este momento"
              }
            ]
          },
          {
            "title": "Graficar los resultados",
            "text": "es/step4.md",
            "verify": [
              {
                "name": "Este paso no tiene verificaciones en este momento",
                "file": "verify4-1.sh",
                "hint": "Este paso no tiene verificaciones en este momento"
              }
            ]
          }
        ],
        "intro": {
          "text": "es/intro.md",
          "title": "Introducción"
        },
        "finish": {
          "text": "es/finish.md",
          "title": "Resumen"
        }
      }
    },
    {
      "lang": "fr",
      "title": "Arrêt précoce du Gradient Stochastique",
      "description": "Le Gradient Stochastique est une technique d'optimisation populaire utilisée pour minimiser une fonction de perte. La technique effectue la descente de gradient étape par étape de manière stochastique, c'est-à-dire en sélectionnant aléatoirement des échantillons à chaque itération. La méthode est efficace, en particulier pour ajuster des modèles linéaires. Cependant, la convergence n'est pas garantie à chaque itération, et la fonction de perte ne diminue pas nécessairement à chaque itération. Dans ce cas, surveiller la convergence sur la fonction de perte peut être difficile. Dans ce laboratoire, nous explorerons la stratégie d'arrêt précoce, qui est une approche pour surveiller la convergence sur un score de validation. Nous utiliserons le modèle SGDClassifier de la bibliothèque scikit-learn et l'ensemble de données MNIST pour illustrer comment l'arrêt précoce peut être utilisé pour obtenir presque la même précision qu'un modèle construit sans arrêt précoce, et réduire considérablement le temps d'entraînement.",
      "meta": {
        "title": "Gradient Stochastique | Ensemble de données MNIST | Arrêt précoce",
        "description": "Explorez la technique d'optimisation Gradient Stochastique, utilisez l'ensemble de données MNIST et découvrez la stratégie d'arrêt précoce pour améliorer l'efficacité de l'entraînement du modèle.",
        "keywords": "Gradient Stochastique, Ensemble de données MNIST, Arrêt précoce, Technique d'optimisation, Apprentissage automatique"
      },
      "details": {
        "steps": [
          {
            "title": "Charger les bibliothèques nécessaires et l'ensemble de données MNIST",
            "text": "fr/step1.md",
            "verify": [
              {
                "name": "Cette étape n'a pas de vérification pour le moment",
                "file": "verify1-1.sh",
                "hint": "Cette étape n'a pas de vérification pour le moment"
              }
            ]
          },
          {
            "title": "Définir l'estimateur et la stratégie d'arrêt précoce",
            "text": "fr/step2.md",
            "verify": [
              {
                "name": "Cette étape n'a pas de vérification pour le moment",
                "file": "verify2-1.sh",
                "hint": "Cette étape n'a pas de vérification pour le moment"
              }
            ]
          },
          {
            "title": "Entraîner et évaluer l'estimateur",
            "text": "fr/step3.md",
            "verify": [
              {
                "name": "Cette étape n'a pas de vérification pour le moment",
                "file": "verify3-1.sh",
                "hint": "Cette étape n'a pas de vérification pour le moment"
              }
            ]
          },
          {
            "title": "Tracer les résultats",
            "text": "fr/step4.md",
            "verify": [
              {
                "name": "Cette étape n'a pas de vérification pour le moment",
                "file": "verify4-1.sh",
                "hint": "Cette étape n'a pas de vérification pour le moment"
              }
            ]
          }
        ],
        "intro": {
          "text": "fr/intro.md",
          "title": "Introduction"
        },
        "finish": {
          "text": "fr/finish.md",
          "title": "Résumé"
        }
      }
    },
    {
      "lang": "de",
      "title": "Frühes Stoppen des Stochastic Gradient Descent",
      "description": "Der Stochastic Gradient Descent ist eine beliebte Optimierungstechnik, die zur Minimierung einer Verlustfunktion verwendet wird. Die Technik führt den Gradientenabstieg schrittweise auf stochastische Weise durch, d.h., indem für jede Iteration zufällig Proben ausgewählt werden. Die Methode ist effizient, insbesondere für die Anpassung linearer Modelle. Allerdings ist die Konvergenz bei jeder Iteration nicht gewährleistet, und die Verlustfunktion muss nicht notwendigerweise bei jeder Iteration abnehmen. In diesem Fall kann es schwierig sein, die Konvergenz der Verlustfunktion zu überwachen. In diesem Lab werden wir die Early-Stopping-Strategie untersuchen, die ein Ansatz zur Überwachung der Konvergenz anhand eines Validierungsscores ist. Wir werden das SGDClassifier-Modell aus der scikit-learn-Bibliothek und den MNIST-Datensatz verwenden, um zu veranschaulichen, wie Early Stopping verwendet werden kann, um fast die gleiche Genauigkeit wie ein Modell ohne Early Stopping zu erreichen und die Trainingszeit erheblich zu reduzieren.",
      "meta": {
        "title": "Stochastic Gradient Descent | MNIST-Datensatz | Frühes Stoppen",
        "description": "Erkunden Sie die Optimierungstechnik Stochastic Gradient Descent, verwenden Sie den MNIST-Datensatz und lernen Sie die Early-Stopping-Strategie kennen, um die Effizienz des Modelltrainings zu verbessern.",
        "keywords": "Stochastic Gradient Descent, MNIST-Datensatz, Frühes Stoppen, Optimierungstechnik, Maschinelles Lernen"
      },
      "details": {
        "steps": [
          {
            "title": "Lade die erforderlichen Bibliotheken und den MNIST-Datensatz",
            "text": "de/step1.md",
            "verify": [
              {
                "name": "Dieser Schritt hat momentan keine Verifizierung",
                "file": "verify1-1.sh",
                "hint": "Dieser Schritt hat momentan keine Verifizierung"
              }
            ]
          },
          {
            "title": "Definiere den Schätzer und die Early-Stopping-Strategie",
            "text": "de/step2.md",
            "verify": [
              {
                "name": "Dieser Schritt hat momentan keine Verifizierung",
                "file": "verify2-1.sh",
                "hint": "Dieser Schritt hat momentan keine Verifizierung"
              }
            ]
          },
          {
            "title": "Trainiere und bewerte den Schätzer",
            "text": "de/step3.md",
            "verify": [
              {
                "name": "Dieser Schritt hat momentan keine Verifizierung",
                "file": "verify3-1.sh",
                "hint": "Dieser Schritt hat momentan keine Verifizierung"
              }
            ]
          },
          {
            "title": "Visualisiere die Ergebnisse",
            "text": "de/step4.md",
            "verify": [
              {
                "name": "Dieser Schritt hat momentan keine Verifizierung",
                "file": "verify4-1.sh",
                "hint": "Dieser Schritt hat momentan keine Verifizierung"
              }
            ]
          }
        ],
        "intro": {
          "text": "de/intro.md",
          "title": "Einführung"
        },
        "finish": {
          "text": "de/finish.md",
          "title": "Zusammenfassung"
        }
      }
    },
    {
      "lang": "ja",
      "title": "確率的勾配降下法の早期終了",
      "description": "確率的勾配降下法は、損失関数を最小化するために使用される一般的な最適化手法です。この手法は、確率的にサンプルを選択して各反復で勾配降下を行うことで、勾配降下を逐次的に行います。この方法は、特に線形モデルのフィッティングに効率的です。ただし、各反復で収束が保証されるわけではなく、各反復で損失関数が必ずしも減少するとは限りません。この場合、損失関数の収束を監視するのは難しい場合があります。この実験では、検証スコアに基づいて収束を監視するアプローチである早期終了戦略を検討します。scikit-learnライブラリのSGDClassifierモデルとMNISTデータセットを使用して、早期終了を使用した場合と早期終了を使用せずに構築されたモデルと比較して、ほぼ同じ精度を達成し、学習時間を大幅に短縮できる方法を示します。",
      "meta": {
        "title": "確率的勾配降下法 | MNISTデータセット | 早期終了",
        "description": "確率的勾配降下法の最適化手法を検討し、MNISTデータセットを使用して、モデルの学習効率を向上させるための早期終了戦略を学びましょう。",
        "keywords": "確率的勾配降下法, MNISTデータセット, 早期終了, 最適化手法, 機械学習"
      },
      "details": {
        "steps": [
          {
            "title": "必要なライブラリとMNISTデータセットを読み込む",
            "text": "ja/step1.md",
            "verify": [
              {
                "name": "このステップでは現在検証はありません",
                "file": "verify1-1.sh",
                "hint": "このステップでは現在検証はありません"
              }
            ]
          },
          {
            "title": "推定器と早期終了戦略を定義する",
            "text": "ja/step2.md",
            "verify": [
              {
                "name": "このステップでは現在検証はありません",
                "file": "verify2-1.sh",
                "hint": "このステップでは現在検証はありません"
              }
            ]
          },
          {
            "title": "推定器を学習して評価する",
            "text": "ja/step3.md",
            "verify": [
              {
                "name": "このステップでは現在検証はありません",
                "file": "verify3-1.sh",
                "hint": "このステップでは現在検証はありません"
              }
            ]
          },
          {
            "title": "結果をプロットする",
            "text": "ja/step4.md",
            "verify": [
              {
                "name": "このステップでは現在検証はありません",
                "file": "verify4-1.sh",
                "hint": "このステップでは現在検証はありません"
              }
            ]
          }
        ],
        "intro": {
          "text": "ja/intro.md",
          "title": "はじめに"
        },
        "finish": {
          "text": "ja/finish.md",
          "title": "まとめ"
        }
      }
    },
    {
      "lang": "ru",
      "title": "Ранняя остановка стохастического градиентного спуска",
      "description": "Стохастический градиентный спуск - популярный метод оптимизации, используемый для минимизации функции потерь. Метод выполняет градиентный спуск шаг за шагом по случайному принципу, то есть при каждой итерации случайным образом выбирает выборки. Метод эффективен, особенно при подгонке линейных моделей. Однако сходимость не гарантируется на каждой итерации, и функция потерь не обязательно уменьшается на каждой итерации. В этом случае отслеживание сходимости по функции потерь может быть сложным. В этом практическом занятии мы изучим стратегию ранней остановки, которая представляет собой метод отслеживания сходимости по валидационному показателю. Мы будем использовать модель SGDClassifier из библиотеки scikit-learn и датасет MNIST, чтобы показать, как ранняя остановка может быть использована для достижения практически той же точности, по сравнению с моделью, построенной без ранней остановки, и значительного сокращения времени обучения.",
      "meta": {
        "title": "Стохастический градиентный спуск | Датасет MNIST | Ранняя остановка",
        "description": "Изучите метод оптимизации стохастический градиентный спуск, используйте датасет MNIST и узнайте о стратегии ранней остановки для повышения эффективности обучения модели.",
        "keywords": "Стохастический градиентный спуск, Датасет MNIST, Ранняя остановка, Метод оптимизации, Machine Learning"
      },
      "details": {
        "steps": [
          {
            "title": "Загрузить необходимые библиотеки и датасет MNIST",
            "text": "ru/step1.md",
            "verify": [
              {
                "name": "На данный момент эта стадия не имеет проверки",
                "file": "verify1-1.sh",
                "hint": "На данный момент эта стадия не имеет проверки"
              }
            ]
          },
          {
            "title": "Определить оценщик и стратегию ранней остановки",
            "text": "ru/step2.md",
            "verify": [
              {
                "name": "На данный момент эта стадия не имеет проверки",
                "file": "verify2-1.sh",
                "hint": "На данный момент эта стадия не имеет проверки"
              }
            ]
          },
          {
            "title": "Обучить и оценить оценщик",
            "text": "ru/step3.md",
            "verify": [
              {
                "name": "На данный момент эта стадия не имеет проверки",
                "file": "verify3-1.sh",
                "hint": "На данный момент эта стадия не имеет проверки"
              }
            ]
          },
          {
            "title": "Построить результаты",
            "text": "ru/step4.md",
            "verify": [
              {
                "name": "На данный момент эта стадия не имеет проверки",
                "file": "verify4-1.sh",
                "hint": "На данный момент эта стадия не имеет проверки"
              }
            ]
          }
        ],
        "intro": {
          "text": "ru/intro.md",
          "title": "Введение"
        },
        "finish": {
          "text": "ru/finish.md",
          "title": "Резюме"
        }
      }
    }
  ]
}
