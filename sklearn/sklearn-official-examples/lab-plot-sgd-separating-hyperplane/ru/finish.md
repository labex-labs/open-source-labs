# Резюме

В этом лабораторном занятии мы научились использовать метод опорных векторов (Support Vector Machines, SVM) с стохастическим градиентным спуском (Stochastic Gradient Descent, SGD) для классификации данных. Мы сгенерировали набор данных, подходящий для классификации, обучили модель SVM с использованием SGD и построили разделяющую гиперплоскость с максимальным отступом. SVM - это мощный алгоритм классификации, который широко используется в машинном обучении для классификации и анализа регрессии. Основная идея метода опорных векторов заключается в нахождении наилучшей разделяющей гиперплоскости, которая разделяет данные на классы с максимально возможным отступом. Стохастический градиентный спуск (SGD) - это алгоритм оптимизации, который используется для нахождения наилучших параметров для алгоритма SVM.
