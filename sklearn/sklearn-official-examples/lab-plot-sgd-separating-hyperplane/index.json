{
  "$schema": "https://cdn.jsdelivr.net/gh/labex-labs/schema/index.json",
  "type": "lab",
  "title": "Plot SGD Separating Hyperplane",
  "description": "In this lab, we will learn how to use Support Vector Machines (SVM) with Stochastic Gradient Descent (SGD) to classify data. SVM is a powerful classification algorithm that is widely used in machine learning for classification and regression analysis. The idea behind SVM is to find the best hyperplane that separates the data into classes with the largest possible margin. The margin is the distance between the hyperplane and the closest data points from each class. Stochastic Gradient Descent (SGD) is an optimization algorithm that is used to find the best parameters for the SVM algorithm.",
  "meta": {
    "title": "Mastering SVM with SGD for Powerful Classification",
    "description": "Discover how to leverage Support Vector Machines and Stochastic Gradient Descent for accurate data classification.",
    "keywords": "machine learning, sgd, classification, scikit-learn, data science, svm, scikit-learn playground"
  },
  "difficulty": "Beginner",
  "time": 15,
  "hidden": false,
  "fee_type": "free",
  "show_in_tutorial": true,
  "details": {
    "steps": [
      {
        "title": "Import necessary libraries and generate data",
        "text": "en/step1.md",
        "verify": [
          {
            "name": "This step has no verification at the moment",
            "file": "verify1-1.sh",
            "hint": "This step has no verification at the moment"
          }
        ],
        "skills": ["ml/sklearn", "sklearn/datasets", "sklearn/linear_model"]
      },
      {
        "title": "Train the SVM model with SGD",
        "text": "en/step2.md",
        "verify": [
          {
            "name": "This step has no verification at the moment",
            "file": "verify2-1.sh",
            "hint": "This step has no verification at the moment"
          }
        ],
        "skills": ["ml/sklearn"]
      },
      {
        "title": "Plot the maximum margin separating hyperplane",
        "text": "en/step3.md",
        "verify": [
          {
            "name": "This step has no verification at the moment",
            "file": "verify3-1.sh",
            "hint": "This step has no verification at the moment"
          }
        ],
        "skills": ["ml/sklearn"]
      }
    ],
    "intro": {
      "text": "en/intro.md",
      "title": "Introduction",
      "background": "setup.sh"
    },
    "finish": {
      "text": "en/finish.md",
      "title": "Summary"
    },
    "assets": {
      "host01": [
        {
          "file": "plot-sgd-separating-hyperplane.ipynb",
          "target": "/home/labex/project",
          "chmod": "ugo+rwx"
        }
      ]
    }
  },
  "backend": {
    "imageid": "jupyter-ubuntu:2204"
  },
  "contributors": [],
  "license": {
    "name": "BSD 3-Clause",
    "url": "https://github.com/scikit-learn/scikit-learn/tree/main/LICENSE",
    "repo": "https://github.com/scikit-learn/scikit-learn"
  },
  "i18n": [
    {
      "lang": "zh",
      "title": "绘制随机梯度下降分离超平面",
      "description": "在本实验中，我们将学习如何使用支持向量机（SVM）和随机梯度下降（SGD）对数据进行分类。支持向量机是一种强大的分类算法，在机器学习中广泛用于分类和回归分析。支持向量机背后的思想是找到最佳超平面，将数据以尽可能大的间隔分隔成不同的类别。间隔是超平面与每个类中最近数据点之间的距离。随机梯度下降（SGD）是一种优化算法，用于为支持向量机算法找到最佳参数。",
      "meta": {
        "title": "掌握使用随机梯度下降的支持向量机进行强大分类",
        "description": "探索如何利用支持向量机和随机梯度下降进行准确的数据分类。",
        "keywords": "机器学习，随机梯度下降，分类，斯科 ikit-learn, 数据科学，支持向量机，斯科 ikit-learn 游乐场"
      },
      "details": {
        "steps": [
          {
            "title": "导入必要的库并生成数据",
            "text": "zh/step1.md",
            "verify": [
              {
                "name": "此步骤目前没有验证",
                "file": "verify1-1.sh",
                "hint": "此步骤目前没有验证"
              }
            ]
          },
          {
            "title": "使用随机梯度下降训练支持向量机模型",
            "text": "zh/step2.md",
            "verify": [
              {
                "name": "此步骤目前没有验证",
                "file": "verify2-1.sh",
                "hint": "此步骤目前没有验证"
              }
            ]
          },
          {
            "title": "绘制最大间隔分离超平面",
            "text": "zh/step3.md",
            "verify": [
              {
                "name": "此步骤目前没有验证",
                "file": "verify3-1.sh",
                "hint": "此步骤目前没有验证"
              }
            ]
          }
        ],
        "intro": {
          "text": "zh/intro.md",
          "title": "介绍"
        },
        "finish": {
          "text": "zh/finish.md",
          "title": "总结"
        }
      }
    },
    {
      "lang": "es",
      "title": "Graficar el hiperplano de separación con SGD",
      "description": "En este laboratorio, aprenderemos a usar Máquinas de Vectores de Soporte (SVM) con Descenso de Gradiente Estocástico (SGD) para clasificar datos. La SVM es un algoritmo de clasificación poderoso que se utiliza ampliamente en el aprendizaje automático para el análisis de clasificación y regresión. La idea detrás de la SVM es encontrar el mejor hiperplano que separa los datos en clases con el margen posiblemente más grande. El margen es la distancia entre el hiperplano y los puntos de datos más cercanos de cada clase. El Descenso de Gradiente Estocástico (SGD) es un algoritmo de optimización que se utiliza para encontrar los mejores parámetros para el algoritmo de SVM.",
      "meta": {
        "title": "Dominando la SVM con SGD para una clasificación poderosa",
        "description": "Descubre cómo aprovechar las Máquinas de Vectores de Soporte y el Descenso de Gradiente Estocástico para una clasificación precisa de datos.",
        "keywords": "aprendizaje automático, sgd, clasificación, scikit-learn, ciencia de datos, svm, playground de scikit-learn"
      },
      "details": {
        "steps": [
          {
            "title": "Importar las bibliotecas necesarias y generar datos",
            "text": "es/step1.md",
            "verify": [
              {
                "name": "Este paso no tiene verificaciones en este momento",
                "file": "verify1-1.sh",
                "hint": "Este paso no tiene verificaciones en este momento"
              }
            ]
          },
          {
            "title": "Entrenar el modelo de SVM con SGD",
            "text": "es/step2.md",
            "verify": [
              {
                "name": "Este paso no tiene verificaciones en este momento",
                "file": "verify2-1.sh",
                "hint": "Este paso no tiene verificaciones en este momento"
              }
            ]
          },
          {
            "title": "Graficar el hiperplano de separación con el margen máximo",
            "text": "es/step3.md",
            "verify": [
              {
                "name": "Este paso no tiene verificaciones en este momento",
                "file": "verify3-1.sh",
                "hint": "Este paso no tiene verificaciones en este momento"
              }
            ]
          }
        ],
        "intro": {
          "text": "es/intro.md",
          "title": "Introducción"
        },
        "finish": {
          "text": "es/finish.md",
          "title": "Resumen"
        }
      }
    },
    {
      "lang": "fr",
      "title": "Tracer l'hyperplan séparateur avec SGD",
      "description": "Dans ce laboratoire, nous allons apprendre à utiliser les Machines à Vecteurs de Support (SVM) avec la Descente de Gradient Stochastique (SGD) pour classifier des données. Les SVM sont un algorithme de classification puissant largement utilisé en apprentissage automatique pour l'analyse de classification et de régression. L'idée derrière les SVM est de trouver le meilleur hyperplan qui sépare les données en classes avec la marge la plus large possible. La marge est la distance entre l'hyperplan et les points de données les plus proches de chaque classe. La Descente de Gradient Stochastique (SGD) est un algorithme d'optimisation utilisé pour trouver les meilleurs paramètres pour l'algorithme des SVM.",
      "meta": {
        "title": "Maîtriser les SVM avec SGD pour une classification puissante",
        "description": "Découvrez comment utiliser les Machines à Vecteurs de Support et la Descente de Gradient Stochastique pour une classification de données précise.",
        "keywords": "apprentissage automatique, sgd, classification, scikit-learn, science des données, svm, terrain de jeu scikit-learn"
      },
      "details": {
        "steps": [
          {
            "title": "Importer les bibliothèques nécessaires et générer des données",
            "text": "fr/step1.md",
            "verify": [
              {
                "name": "Cette étape n'a pas de vérification pour le moment",
                "file": "verify1-1.sh",
                "hint": "Cette étape n'a pas de vérification pour le moment"
              }
            ]
          },
          {
            "title": "Entraîner le modèle SVM avec SGD",
            "text": "fr/step2.md",
            "verify": [
              {
                "name": "Cette étape n'a pas de vérification pour le moment",
                "file": "verify2-1.sh",
                "hint": "Cette étape n'a pas de vérification pour le moment"
              }
            ]
          },
          {
            "title": "Tracer l'hyperplan séparateur de la marge maximale",
            "text": "fr/step3.md",
            "verify": [
              {
                "name": "Cette étape n'a pas de vérification pour le moment",
                "file": "verify3-1.sh",
                "hint": "Cette étape n'a pas de vérification pour le moment"
              }
            ]
          }
        ],
        "intro": {
          "text": "fr/intro.md",
          "title": "Introduction"
        },
        "finish": {
          "text": "fr/finish.md",
          "title": "Résumé"
        }
      }
    },
    {
      "lang": "de",
      "title": "Zeichnen der Hyperebene mit SGD",
      "description": "In diesem Lab werden wir lernen, wie man Support Vector Machines (SVM) mit Stochastic Gradient Descent (SGD) verwendet, um Daten zu klassifizieren. SVM ist ein leistungsstarkes Klassifikationsalgorithmus, der in der Maschinellen Lernung weit verbreitet zur Klassifizierung und Regressionsanalyse eingesetzt wird. Das Grundprinzip hinter SVM besteht darin, die beste Hyperebene zu finden, die die Daten in Klassen mit möglichst großem Margin trennt. Der Margin ist die Entfernung zwischen der Hyperebene und den nächsten Datenpunkten aus jeder Klasse. Stochastic Gradient Descent (SGD) ist ein Optimierungsalgorithmus, der verwendet wird, um die besten Parameter für den SVM-Algorithmus zu finden.",
      "meta": {
        "title": "Meisterklasse: SVM mit SGD für leistungsstarke Klassifizierung",
        "description": "Entdecken Sie, wie Sie Support Vector Machines und Stochastic Gradient Descent für eine genaue Datenklassifizierung nutzen können.",
        "keywords": "Maschinelles Lernen, SGD, Klassifizierung, Scikit-learn, Datenwissenschaft, SVM, Scikit-learn Spielplatz"
      },
      "details": {
        "steps": [
          {
            "title": "Importieren der erforderlichen Bibliotheken und Generieren von Daten",
            "text": "de/step1.md",
            "verify": [
              {
                "name": "Dieser Schritt hat momentan keine Verifizierung",
                "file": "verify1-1.sh",
                "hint": "Dieser Schritt hat momentan keine Verifizierung"
              }
            ]
          },
          {
            "title": "Trainiere das SVM-Modell mit SGD",
            "text": "de/step2.md",
            "verify": [
              {
                "name": "Dieser Schritt hat momentan keine Verifizierung",
                "file": "verify2-1.sh",
                "hint": "Dieser Schritt hat momentan keine Verifizierung"
              }
            ]
          },
          {
            "title": "Zeichne die Hyperebene mit dem größten Margin",
            "text": "de/step3.md",
            "verify": [
              {
                "name": "Dieser Schritt hat momentan keine Verifizierung",
                "file": "verify3-1.sh",
                "hint": "Dieser Schritt hat momentan keine Verifizierung"
              }
            ]
          }
        ],
        "intro": {
          "text": "de/intro.md",
          "title": "Einführung"
        },
        "finish": {
          "text": "de/finish.md",
          "title": "Zusammenfassung"
        }
      }
    },
    {
      "lang": "ja",
      "title": "SGD による分離ハイパープレーンの描画",
      "description": "この実験では、確率的勾配降下法（SGD）を用いたサポートベクターマシン（SVM）を使ってデータを分類する方法を学びます。SVM は、機械学習において分類と回帰分析に広く使われる強力な分類アルゴリズムです。SVM の背後にある考え方は、データをクラスに分離する最適なハイパープレーンをできるだけ大きなマージンで見つけることです。マージンとは、ハイパープレーンと各クラスの最も近いデータポイントとの距離です。確率的勾配降下法（SGD）は、SVM アルゴリズムの最適なパラメータを見つけるために使われる最適化アルゴリズムです。",
      "meta": {
        "title": "強力な分類のための SGD を使った SVM のマスター",
        "description": "サポートベクターマシンと確率的勾配降下法を活用して正確なデータ分類を行う方法を学びましょう。",
        "keywords": "機械学習，SGD, 分類，scikit-learn, データサイエンス，SVM, scikit-learn プレイグラウンド"
      },
      "details": {
        "steps": [
          {
            "title": "必要なライブラリをインポートしてデータを生成する",
            "text": "ja/step1.md",
            "verify": [
              {
                "name": "このステップでは現在検証はありません",
                "file": "verify1-1.sh",
                "hint": "このステップでは現在検証はありません"
              }
            ]
          },
          {
            "title": "SGD を使って SVM モデルを学習する",
            "text": "ja/step2.md",
            "verify": [
              {
                "name": "このステップでは現在検証はありません",
                "file": "verify2-1.sh",
                "hint": "このステップでは現在検証はありません"
              }
            ]
          },
          {
            "title": "最大マージン分離ハイパープレーンを描画する",
            "text": "ja/step3.md",
            "verify": [
              {
                "name": "このステップでは現在検証はありません",
                "file": "verify3-1.sh",
                "hint": "このステップでは現在検証はありません"
              }
            ]
          }
        ],
        "intro": {
          "text": "ja/intro.md",
          "title": "はじめに"
        },
        "finish": {
          "text": "ja/finish.md",
          "title": "まとめ"
        }
      }
    },
    {
      "lang": "ru",
      "title": "Построение разделяющей гиперплоскости с использованием SGD",
      "description": "В этом лабораторном занятии мы научимся использовать метод опорных векторов (Support Vector Machines, SVM) с стохастическим градиентным спуском (Stochastic Gradient Descent, SGD) для классификации данных. SVM - это мощный алгоритм классификации, который широко используется в машинном обучении для классификации и анализа регрессии. Основная идея метода опорных векторов заключается в нахождении наилучшей разделяющей гиперплоскости, которая разделяет данные на классы с максимально возможным отступом. Отступ - это расстояние между гиперплоскостью и ближайшими точками данных из каждого класса. Стохастический градиентный спуск (SGD) - это алгоритм оптимизации, который используется для нахождения наилучших параметров для алгоритма SVM.",
      "meta": {
        "title": "Мастерство в использовании SVM с SGD для мощной классификации",
        "description": "Откройте, как использовать методы опорных векторов и стохастический градиентный спуск для точной классификации данных.",
        "keywords": "машинное обучение, sgd, классификация, scikit-learn, наука о данных, svm, scikit-learn playground"
      },
      "details": {
        "steps": [
          {
            "title": "Импортировать необходимые библиотеки и сгенерировать данные",
            "text": "ru/step1.md",
            "verify": [
              {
                "name": "На данный момент эта стадия не имеет проверки",
                "file": "verify1-1.sh",
                "hint": "На данный момент эта стадия не имеет проверки"
              }
            ]
          },
          {
            "title": "Обучить модель SVM с использованием SGD",
            "text": "ru/step2.md",
            "verify": [
              {
                "name": "На данный момент эта стадия не имеет проверки",
                "file": "verify2-1.sh",
                "hint": "На данный момент эта стадия не имеет проверки"
              }
            ]
          },
          {
            "title": "Построить разделяющую гиперплоскость с максимальным отступом",
            "text": "ru/step3.md",
            "verify": [
              {
                "name": "На данный момент эта стадия не имеет проверки",
                "file": "verify3-1.sh",
                "hint": "На данный момент эта стадия не имеет проверки"
              }
            ]
          }
        ],
        "intro": {
          "text": "ru/intro.md",
          "title": "Введение"
        },
        "finish": {
          "text": "ru/finish.md",
          "title": "Резюме"
        }
      }
    }
  ]
}
