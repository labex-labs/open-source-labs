# はじめに

この実験では、確率的勾配降下法（SGD）を用いたサポートベクターマシン（SVM）を使ってデータを分類する方法を学びます。SVMは、機械学習において分類と回帰分析に広く使われる強力な分類アルゴリズムです。SVMの背後にある考え方は、データをクラスに分離する最適なハイパープレーンをできるだけ大きなマージンで見つけることです。マージンとは、ハイパープレーンと各クラスから最も近いデータポイントとの距離です。確率的勾配降下法（SGD）は、SVMアルゴリズムの最適なパラメータを見つけるために使われる最適化アルゴリズムです。

## VMのヒント

VMの起動が完了したら、左上隅をクリックして**ノートブック**タブに切り替えて、Jupyter Notebookを使って練習しましょう。

時々、Jupyter Notebookが読み込み終了するまで数秒待つ必要がある場合があります。Jupyter Notebookの制限により、操作の検証を自動化することはできません。

学習中に問題に遭遇した場合は、Labbyにお問い合わせください。セッション後にフィードバックを提供してください。すぐに問題を解決いたします。
