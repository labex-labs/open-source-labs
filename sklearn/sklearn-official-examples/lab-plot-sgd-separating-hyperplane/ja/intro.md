# はじめに

この実験では、確率的勾配降下法（SGD）を用いたサポートベクターマシン（SVM）を使ってデータを分類する方法を学びます。SVM は、機械学習において分類と回帰分析に広く使われる強力な分類アルゴリズムです。SVM の背後にある考え方は、データをクラスに分離する最適なハイパープレーンをできるだけ大きなマージンで見つけることです。マージンとは、ハイパープレーンと各クラスから最も近いデータポイントとの距離です。確率的勾配降下法（SGD）は、SVM アルゴリズムの最適なパラメータを見つけるために使われる最適化アルゴリズムです。

## VM のヒント

VM の起動が完了したら、左上隅をクリックして**ノートブック**タブに切り替えて、Jupyter Notebook を使って練習しましょう。

時々、Jupyter Notebook が読み込み終了するまで数秒待つ必要がある場合があります。Jupyter Notebook の制限により、操作の検証を自動化することはできません。

学習中に問題に遭遇した場合は、Labby にお問い合わせください。セッション後にフィードバックを提供してください。すぐに問題を解決いたします。
