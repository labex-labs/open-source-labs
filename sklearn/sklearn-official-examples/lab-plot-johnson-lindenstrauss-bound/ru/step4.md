# Обзор

В этом лабораторном занятии мы исследовали теоретические границы леммы Джонсона-Линденштрасса для эмбеддинга с использованием случайных проекций и проверили ее эмпирически с помощью Python scikit-learn. Мы построили график минимального числа размерностей, необходимых для гарантии `eps`-эмбеддинга для возрастающего числа выборок `n_samples`. Мы также проверили границы Джонсона-Линденштрасса эмпирически на наборе текстовых документов 20 newsgroups или на наборе цифр. Мы проектировали 300 документов с общим количеством 100 тыс. признаков с использованием разреженной случайной матрицы в более мелкие евклидовы пространства с различными значениями для целевого числа размерностей `n_components`. Мы можем видеть, что для малых значений `n_components` распределение имеет широкий диапазон с большим количеством искаженных пар и смещенным распределением, в то время как для больших значений `n_components` искажение контролируется, и расстояния хорошо сохраняются при случайной проекции.
