# Resumen

En este laboratorio, exploramos los límites teóricos del lema de Johnson-Lindenstrauss para la incrustación con proyecciones aleatorias y lo validamos empíricamente utilizando scikit-learn de Python. Graficamos el número mínimo de dimensiones necesario para garantizar una incrustación de `eps` para un número creciente de muestras `n_samples`. También validamos los límites de Johnson-Lindenstrauss empíricamente en el conjunto de datos de documentos de texto 20 newsgroups o en el conjunto de datos de dígitos. Proyectamos 300 documentos con 100k características en total usando una matriz aleatoria esparsa a espacios euclidianos más pequeños con varios valores para el número objetivo de dimensiones `n_components`. Podemos ver que para valores bajos de `n_components` la distribución es amplia con muchos pares distorsionados y una distribución sesgada mientras que para valores más grandes de `n_components` la distorsión está controlada y las distancias se preservan bien por la proyección aleatoria.
