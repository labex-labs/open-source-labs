# Resumen

En este laboratorio, aprendimos sobre el early stopping en gradient boosting, que nos permite encontrar el menor número de iteraciones suficiente para construir un modelo que se generalice bien a datos no vistos. Comparamos el rendimiento de un modelo de gradient boosting con y sin early stopping y observamos que el early stopping puede reducir significativamente el tiempo de entrenamiento, el uso de memoria y la latencia de predicción.
