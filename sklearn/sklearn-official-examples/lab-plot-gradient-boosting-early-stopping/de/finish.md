# Zusammenfassung

In diesem Lab haben wir uns mit Early Stopping in Gradient Boosting beschäftigt, was uns ermöglicht, die geringste Anzahl an Iterationen zu finden, die ausreichen, um ein Modell zu erstellen, das gut auf unbekannte Daten generalisiert. Wir haben die Leistung eines Gradient Boosting-Modells mit und ohne Early Stopping verglichen und festgestellt, dass Early Stopping die Trainingszeit, den Arbeitsspeicherbedarf und die Vorhersageverzögerung erheblich reduzieren kann.
