# Introdução

O boosting de gradientes é uma técnica de conjunto onde vários aprendizes fracos (árvores de regressão) são combinados para produzir um único modelo poderoso, de forma iterativa. O suporte a parada antecipada no Boosting de Gradientes permite-nos encontrar o menor número de iterações suficiente para construir um modelo que generalize bem para dados não vistos.

## Dicas de Máquina Virtual

Após o arranque da VM, clique no canto superior esquerdo para mudar para a aba **Notebook** para aceder ao [Jupyter Notebook](https://support.labex.io/en/labex-vm/jupyter) para praticar.

Por vezes, pode ser necessário esperar alguns segundos para o Jupyter Notebook terminar de carregar. A validação das operações não pode ser automatizada devido a limitações no Jupyter Notebook.

Se tiver problemas durante a aprendizagem, não hesite em contactar o Labby. Forneça feedback após a sessão e resolveremos prontamente o problema para si.
