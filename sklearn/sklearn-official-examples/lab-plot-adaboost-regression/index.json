{
  "type": "lab",
  "title": "Boosted Decision Tree Regression",
  "description": "In this lab, we will be using Python's Scikit-Learn library to perform Boosted Decision Tree Regression on a 1D sinusoidal dataset. We will compare the performance of a single Decision Tree Regressor with that of an AdaBoost Regressor with 300 Decision Tree Regressors as base learners.",
  "meta": {
    "title": "Boosted Decision Tree Regression | Python Scikit-Learn | Sinusoidal Data",
    "description": "Learn how to perform Boosted Decision Tree Regression on a 1D sinusoidal dataset using Python's Scikit-Learn library.",
    "keywords": "Boosted Decision Tree Regression, Python, Scikit-Learn, Sinusoidal Data, Machine Learning"
  },
  "difficulty": "Beginner",
  "time": 15,
  "hidden": false,
  "fee_type": "free",
  "show_in_tutorial": true,
  "details": {
    "steps": [
      {
        "title": "Preparing the data",
        "text": "en/step1.md",
        "verify": [
          {
            "name": "This step has no verification at the moment",
            "file": "verify1.sh",
            "hint": "This step has no verification at the moment"
          }
        ],
        "skills": ["ml/sklearn"]
      },
      {
        "title": "Training and prediction with DecisionTree and AdaBoost Regressors",
        "text": "en/step2.md",
        "verify": [
          {
            "name": "This step has no verification at the moment",
            "file": "verify2.sh",
            "hint": "This step has no verification at the moment"
          }
        ],
        "skills": ["ml/sklearn", "sklearn/ensemble", "sklearn/tree"]
      },
      {
        "title": "Plotting the results",
        "text": "en/step3.md",
        "verify": [
          {
            "name": "This step has no verification at the moment",
            "file": "verify3.sh",
            "hint": "This step has no verification at the moment"
          }
        ],
        "skills": ["ml/sklearn"]
      }
    ],
    "intro": {
      "text": "en/intro.md",
      "background": "setup.sh",
      "title": "Introduction"
    },
    "finish": {
      "text": "en/finish.md",
      "title": "Summary"
    },
    "assets": {
      "host01": [
        {
          "file": "plot-adaboost-regression.ipynb",
          "target": "/home/labex/project",
          "chmod": "ugo+rwx"
        }
      ]
    }
  },
  "backend": {
    "imageid": "jupyter-ubuntu:2204"
  },
  "contributors": [],
  "license": {
    "name": "BSD 3-Clause",
    "url": "https://github.com/scikit-learn/scikit-learn/tree/main/LICENSE",
    "repo": "https://github.com/scikit-learn/scikit-learn"
  },
  "i18n": [
    {
      "lang": "zh",
      "title": "提升决策树回归",
      "description": "在本实验中，我们将使用 Python 的 Scikit-Learn 库对一维正弦数据集执行提升决策树回归。我们将比较单个决策树回归器与以 300 个决策树回归器作为基学习器的 AdaBoost 回归器的性能。",
      "meta": {
        "title": "提升决策树回归 | Python Scikit-Learn | 正弦数据",
        "description": "学习如何使用 Python 的 Scikit-Learn 库对一维正弦数据集执行提升决策树回归。",
        "keywords": "提升决策树回归, Python, Scikit-Learn, 正弦数据, 机器学习"
      },
      "details": {
        "steps": [
          {
            "title": "准备数据",
            "text": "zh/step1.md",
            "verify": [
              {
                "name": "此步骤目前没有验证",
                "file": "verify1.sh",
                "hint": "此步骤目前没有验证"
              }
            ]
          },
          {
            "title": "使用决策树和 AdaBoost 回归器进行训练和预测",
            "text": "zh/step2.md",
            "verify": [
              {
                "name": "此步骤目前没有验证",
                "file": "verify2.sh",
                "hint": "此步骤目前没有验证"
              }
            ]
          },
          {
            "title": "绘制结果",
            "text": "zh/step3.md",
            "verify": [
              {
                "name": "此步骤目前没有验证",
                "file": "verify3.sh",
                "hint": "此步骤目前没有验证"
              }
            ]
          }
        ],
        "intro": {
          "text": "zh/intro.md",
          "title": "介绍"
        },
        "finish": {
          "text": "zh/finish.md",
          "title": "总结"
        }
      }
    }
  ]
}
