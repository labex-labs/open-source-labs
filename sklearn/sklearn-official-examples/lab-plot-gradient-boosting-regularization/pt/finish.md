# Resumo

Neste laboratório, aprendemos como implementar diferentes estratégias de regularização para Gradient Boosting usando o scikit-learn. Utilizamos a função de perda de desvio binomial e o conjunto de dados `make_hastie_10_2`. Implementamos diferentes estratégias de regularização, como sem encolhimento, taxa de aprendizado = 0,2, subsample = 0,5 e máximo de características = 2. Finalmente, plotamos o desvio do conjunto de teste para cada estratégia de regularização para comparar seu desempenho.
