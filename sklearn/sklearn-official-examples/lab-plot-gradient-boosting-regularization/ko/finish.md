# 요약

이 실험에서는 scikit-learn 을 사용하여 Gradient Boosting 에 대한 다양한 정규화 전략을 구현하는 방법을 배웠습니다. 이 실험에서는 이항 편차 손실 함수와 make_hastie_10_2 데이터셋을 사용했습니다. 축소 없음, 학습률 = 0.2, 샘플링 비율 = 0.5, 최대 특징 = 2 와 같은 다양한 정규화 전략을 구현했습니다. 마지막으로 각 정규화 전략에 대한 테스트 세트 편차를 플롯하여 성능을 비교했습니다.
