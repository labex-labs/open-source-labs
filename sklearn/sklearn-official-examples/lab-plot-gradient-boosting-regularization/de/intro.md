# Einführung

In diesem Lab lernst du, wie du verschiedene Regularisierungstrategien für Gradient Boosting mit scikit-learn implementierst. Regularisierung ist eine Technik, die hilft, Overfitting zu vermeiden, was ein häufiges Problem in Machine-Learning-Modellen ist. Wir werden die binomiale Devianzverlustfunktion und den make_hastie_10_2-Datensatz für dieses Lab verwenden.

## VM-Tipps

Nachdem der VM-Start abgeschlossen ist, klicke in der oberen linken Ecke, um zur Registerkarte **Notebook** zu wechseln und Jupyter Notebook für die Übung zu nutzen.

Manchmal musst du einige Sekunden warten, bis Jupyter Notebook vollständig geladen ist. Die Validierung von Vorgängen kann aufgrund der Einschränkungen in Jupyter Notebook nicht automatisiert werden.

Wenn du bei der Lernphase Probleme hast, kannst du Labby gerne fragen. Gib nach der Sitzung Feedback, und wir werden das Problem für dich prompt beheben.
