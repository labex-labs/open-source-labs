# Zusammenfassung

In diesem Lab haben wir den Prozess der Implementierung der rekursiven Feature-Eliminierung mit Kreuzvalidierung (RFECV) mit scikit-learn durchlaufen. Wir haben eine Klassifizierungsaufgabe mit 15 Features erzeugt, von denen 3 informativ, 2 redundant und 10 nicht-informativ waren. Wir haben die logistische Regression als Schätzer und die stratifizierte k-fache Kreuzvalidierung mit 5 Folds verwendet. Wir haben die Anzahl der ausgewählten Features gegen die Kreuzvalidierungsscores geplottet. Wir haben festgestellt, dass die optimale Anzahl an Features 3 war, was dem wahren generativen Modell entsprach. Wir haben auch eine Plateau von gleichwertigen Scores für 3 bis 5 ausgewählte Features bemerkt, die auf die Einführung von korrelierten Features zurückzuführen war.
