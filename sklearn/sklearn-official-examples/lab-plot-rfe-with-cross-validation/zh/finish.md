# 总结

在本实验中，我们经历了使用 scikit-learn 实现带交叉验证的递归特征消除（RFECV）的过程。我们生成了一个具有 15 个特征的分类任务，其中 3 个是信息性的，2 个是冗余的，10 个是非信息性的。我们使用逻辑回归作为估计器，并采用 5 折分层 k 折交叉验证。我们绘制了所选特征数量与交叉验证分数的关系图。我们发现最优特征数量为 3，这与真实的生成模型相对应。由于引入了相关特征，我们还注意到对于 3 到 5 个所选特征存在等效分数的平稳期。
