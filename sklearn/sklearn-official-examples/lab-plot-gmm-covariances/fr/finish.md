# Sommaire

Ce tutoriel a démontré l'utilisation de différents types de covariance pour les modèles de mélange gaussien (GMM) en Python. Nous avons utilisé l'ensemble de données Iris comme exemple et comparé les GMM avec des matrices de covariance sphérique, diagonale, complète et liée dans l'ordre croissant de performance. Nous avons tracé les étiquettes prédites sur les données d'entraînement et de test conservées et montré que la covariance complète est propice au surapprentissage sur de petits ensembles de données et ne généralise pas bien aux données de test conservées.
