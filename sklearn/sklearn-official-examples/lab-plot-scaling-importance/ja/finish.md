# まとめ

この実験では、機械学習における特徴量のスケーリングの重要性と、そのモデル性能への影響について学びました。特徴量のスケーリングがK近傍法モデルと主成分分析による次元削減に与える影響を検討しました。また、主成分分析により次元削減されたデータを使ってロジスティック回帰モデルを学習し、特徴量のスケーリングがモデル性能に与える影響を評価しました。次元削減を行う前に特徴量をスケーリングすると、同じオーダーの大きさの成分が得られ、クラスの分離性が向上し、モデル性能が向上することがわかりました。
