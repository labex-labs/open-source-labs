# 总结

在本实验中，我们了解了机器学习中特征缩放的重要性及其对模型性能的影响。我们探讨了特征缩放对 K 近邻模型和主成分分析（PCA）降维的影响。我们还使用经过 PCA 降维的数据训练了一个逻辑回归模型，以评估特征缩放对模型性能的影响。我们发现，在降维之前对特征进行缩放会得到具有相同数量级的成分，并提高类别的可分离性，从而带来更好的模型性能。
