# Резюме

В этом практическом занятии мы научились использовать логистическую регрессию для классификации рукописных цифр из набора данных MNIST. Мы также узнали, как использовать алгоритм SAGA с L1-штрафом для логистической регрессии. Мы достигли точности более 0,8 с разреженным вектором весов, что делает модель более интерпретируемой. Однако, мы также отметили, что эта точность значительно ниже той, которую можно достичь с помощью L2-штрафованной линейной модели или нелинейной многослойной перцептронной модели на этом наборе данных.
