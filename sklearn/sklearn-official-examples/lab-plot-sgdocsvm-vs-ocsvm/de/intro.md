# Einführung

In diesem Lab werden wir demonstrieren, wie man Stochastic Gradient Descent (SGD) verwendet, um die Lösung eines One-Class SVM im Fall eines RBF-Kernels zu approximieren.

Wir werden die Ergebnisse dieser Approximation mit den Ergebnissen vergleichen, die man mit einem kernelisierten Ansatz für ein One-Class SVM erhält. Der Zweck dieses Labs ist es nicht, die Vorteile der Approximation in Bezug auf die Rechenzeit zu zeigen, sondern vielmehr zu demonstrieren, dass man ähnliche Ergebnisse mit SGD auf einem Toy-Datensatz erzielen kann.

## VM-Tipps

Nachdem die VM gestartet ist, klicken Sie in der oberen linken Ecke, um zur Registerkarte **Notebook** zu wechseln und Jupyter Notebook für die Übung zu nutzen.

Manchmal müssen Sie einige Sekunden warten, bis Jupyter Notebook vollständig geladen ist. Die Validierung von Vorgängen kann aufgrund von Einschränkungen in Jupyter Notebook nicht automatisiert werden.

Wenn Sie bei der Lernphase Probleme haben, können Sie Labby gerne fragen. Geben Sie nach der Sitzung Feedback, und wir werden das Problem für Sie prompt beheben.
