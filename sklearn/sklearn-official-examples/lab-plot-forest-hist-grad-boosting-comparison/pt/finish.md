# Resumo

Neste laboratório, comparamos o desempenho de dois modelos de conjunto populares, Floresta Aleatória e Reforço de Gradiente Histograma, para um conjunto de dados de regressão em termos de pontuação e tempo de computação. Variamos os parâmetros que controlam o número de árvores de acordo com cada estimador e plotamos os resultados para visualizar o trade-off entre o tempo de computação decorrido e a pontuação média de teste. Observamos que os modelos HGBT dominam uniformemente os modelos RF no "trade-off entre pontuação de teste e velocidade de treinamento" e o "trade-off entre pontuação de teste e velocidade de predição" também pode ser mais favorável aos HGBT. O HGBT quase sempre oferece um trade-off velocidade-precisão mais favorável do que o RF, seja com os hiperparâmetros padrão ou incluindo o custo de ajuste de hiperparâmetros.
