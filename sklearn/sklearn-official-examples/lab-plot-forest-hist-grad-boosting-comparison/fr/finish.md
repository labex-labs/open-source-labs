# Sommaire

Dans ce laboratoire, nous avons comparé les performances de deux modèles d'ensemble populaires, Random Forest et Histogram Gradient Boosting, pour un ensemble de données de régression en termes de score et de temps de calcul. Nous avons fait varier les paramètres qui contrôlent le nombre d'arbres selon chaque estimateur et avons tracé les résultats pour visualiser le compromis entre le temps de calcul écoulé et la moyenne du score de test. Nous avons observé que les modèles HGBT dominent uniformément les modèles RF dans le "compromis score de test vs vitesse d'entraînement" et que le "compromis score de test vs vitesse de prédiction" peut également être plus favorable aux HGBT. L'HGBT offre presque toujours un compromis vitesse - précision plus favorable que le RF, que ce soit avec les hyper-paramètres par défaut ou en incluant le coût d'ajustement des hyper-paramètres.
