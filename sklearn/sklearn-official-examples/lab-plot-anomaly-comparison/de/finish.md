# Zusammenfassung

In diesem Lab wurden verschiedene Anomalieerkennungsalgorithmen auf zweidimensionalen Datensätzen verglichen. Die Datensätze enthielten eine oder zwei Modi (Regionen mit hoher Dichte), um die Fähigkeit der Algorithmen zur Bewältigung von multimodalen Daten zu illustrieren. Die Entscheidunggrenzen zwischen Inlier und Outlier wurden in Schwarz dargestellt, ausgenommen für den Local Outlier Factor (LOF), da er keine Predict-Methode hatte, die auf neue Daten angewendet werden konnte, wenn er zur Anomalieerkennung verwendet wurde. Es stellte sich heraus, dass die :class:`~sklearn.svm.OneClassSVM` empfindlich gegenüber Ausreißern war und daher für die Anomalieerkennung nicht sehr gut performierte. Die :class:`sklearn.linear_model.SGDOneClassSVM` war eine Implementierung der One-Class SVM auf der Grundlage des stochastischen Gradientenabstiegs (SGD). Die :class:`sklearn.covariance.EllipticEnvelope` nahm an, dass die Daten normalverteilt seien, und lernte eine Ellipse, und :class:`~sklearn.ensemble.IsolationForest` und :class:`~sklearn.neighbors.LocalOutlierFactor` schienen für multimodale Datensätze ziemlich gut zu funktionieren.
