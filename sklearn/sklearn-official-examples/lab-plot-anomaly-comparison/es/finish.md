# Resumen

Esta práctica comparó diferentes algoritmos de detección de anomalías en conjuntos de datos bidimensionales. Los conjuntos de datos contenían una o dos modalidades (regiones de alta densidad) para ilustrar la capacidad de los algoritmos para lidiar con datos multimodales. Los límites de decisión entre valores normales e atípicos se mostraron en negro, excepto para Local Outlier Factor (LOF), ya que no tenía un método de predicción que se pudiera aplicar a nuevos datos cuando se utilizaba para la detección de valores atípicos. Se encontró que :class:`~sklearn.svm.OneClassSVM` era sensible a los valores atípicos y, por lo tanto, no funcionó muy bien para la detección de valores atípicos. :class:`sklearn.linear_model.SGDOneClassSVM` era una implementación de One-Class SVM basada en el descenso del gradiente estocástico (SGD). :class:`sklearn.covariance.EllipticEnvelope` asumía que los datos eran gaussianos y aprendía una elipse, y :class:`~sklearn.ensemble.IsolationForest` y :class:`~sklearn.neighbors.LocalOutlierFactor` parecieron funcionar razonablemente bien para conjuntos de datos multimodales.
