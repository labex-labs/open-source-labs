# Introducción

Esta práctica mostrará cómo comparar la clasificación de vecinos más cercanos con y sin Análisis de Componentes Vecinales (NCA, Neighborhood Components Analysis). Graficaremos los límites de decisión de clase dados por un clasificador de vecinos más cercanos cuando se utiliza la distancia euclidiana en las características originales, en comparación con el uso de la distancia euclidiana después de la transformación aprendida por Análisis de Componentes Vecinales. Este último tiene como objetivo encontrar una transformación lineal que maximice la precisión de clasificación de vecinos más cercanos (estocástica) en el conjunto de entrenamiento. Utilizaremos el conjunto de datos Iris que contiene 3 clases de 50 instancias cada una.

## Consejos sobre la VM

Una vez finalizada la inicialización de la VM, haga clic en la esquina superior izquierda para cambiar a la pestaña **Cuaderno** para acceder a Jupyter Notebook y practicar.

A veces, es posible que tenga que esperar unos segundos a que Jupyter Notebook termine de cargarse. La validación de las operaciones no puede automatizarse debido a las limitaciones de Jupyter Notebook.

Si tiene problemas durante el aprendizaje, no dude en preguntar a Labby. Deje sus comentarios después de la sesión y resolveremos rápidamente el problema para usted.
