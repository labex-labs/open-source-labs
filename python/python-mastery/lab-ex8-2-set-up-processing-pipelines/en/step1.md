# Basic Generator Pipeline with CSV Data

In this step, we're going to learn how to create a basic processing pipeline using generators. But first, let's understand what generators are. Generators are a special type of iterator in Python. Unlike regular iterators that might load all data into memory at once, generators generate values on-demand. This is extremely useful when dealing with large data streams because it saves memory. Instead of having to store the entire dataset in memory, the generator produces values one by one as you need them.

## Understanding Generators

A generator is essentially a function that returns an iterator. When you iterate over this iterator, it produces a sequence of values. The way you write a generator function is similar to a regular function, but there's a key difference. Instead of using the `return` statement, a generator function uses the `yield` statement. The `yield` statement has a unique behavior. It pauses the function and saves its current state. When the next value is requested, the function continues from where it left off. This allows the generator to produce values incrementally without having to start from the beginning every time.

## Using the follow() Function

The `follow()` function you created earlier works in a similar way to the Unix `tail -f` command. The `tail -f` command continuously monitors a file for new content, and so does the `follow()` function. Now, let's use it to create a simple processing pipeline.

### Step 1: Open a new terminal window

First, open a new terminal window in the WebIDE. You can do this by going to `Terminal â†’ New Terminal`. This new terminal will be where we'll run our Python commands.

### Step 2: Start a Python interactive shell

Once the new terminal is open, start a Python interactive shell. You can do this by entering the following command in the terminal:

```bash
python3
```

The Python interactive shell allows you to run Python code line by line and see the results immediately.

### Step 3: Import the `follow` function and set up the pipeline

Now, we'll import the `follow` function and set up a basic pipeline to read the stock data. In the Python interactive shell, enter the following code:

```python
>>> from follow import follow
>>> import csv
>>> lines = follow('stocklog.csv')
>>> rows = csv.reader(lines)
>>> for row in rows:
...     print(row)
...
```

Here's what each line does:

- `from follow import follow`: This imports the `follow` function from the `follow` module.
- `import csv`: This imports the `csv` module, which is used to read and write CSV files in Python.
- `lines = follow('stocklog.csv')`: This calls the `follow` function with the file name `stocklog.csv`. The `follow` function returns a generator that yields new lines as they're added to the file.
- `rows = csv.reader(lines)`: The `csv.reader()` function takes the lines generated by the `follow` function and parses them into rows of CSV data.
- The `for` loop iterates through these rows and prints each one.

### Step 4: Check the output

After running the code, you should see output similar to this (your data will vary):

```
['BA', '98.35', '6/11/2007', '09:41.07', '0.16', '98.25', '98.35', '98.31', '158148']
['AA', '39.63', '6/11/2007', '09:41.07', '-0.03', '39.67', '39.63', '39.31', '270224']
['XOM', '82.45', '6/11/2007', '09:41.07', '-0.23', '82.68', '82.64', '82.41', '748062']
['PG', '62.95', '6/11/2007', '09:41.08', '-0.12', '62.80', '62.97', '62.61', '454327']
...
```

This output indicates that you've successfully created a data pipeline. The `follow()` function generates lines from the file, and these lines are then passed to the `csv.reader()` function, which parses them into rows of data.

If you've seen enough output, you can stop the execution by pressing `Ctrl+C`.

## What's Happening?

Let's break down what's going on in this pipeline:

1. `follow('stocklog.csv')` creates a generator. This generator keeps track of the `stocklog.csv` file and yields new lines as they're added to the file.
2. `csv.reader(lines)` takes the lines generated by the `follow` function and parses them into CSV row data. It understands the structure of CSV files and splits the lines into individual values.
3. The `for` loop then iterates through these rows, printing each one. This allows you to see the data in a readable format.

This is a simple example of a data processing pipeline using generators. In the next steps, we'll build more complex and useful pipelines.
