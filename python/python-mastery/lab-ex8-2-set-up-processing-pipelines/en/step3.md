# Building a More Complex Data Pipeline

Now, we're going to take our data pipeline to the next level by adding filtering and improving the presentation of the data. This will make it easier to analyze and understand the information we're working with. We'll be making changes to our `ticker.py` script. Filtering the data will help us focus on the specific information we're interested in, and presenting it in a nicely formatted table will make it more readable.

## Updating the ticker.py File

1. First, open your `ticker.py` file in the WebIDE. The WebIDE is a tool that allows you to write and edit code directly in your browser. It provides a convenient environment for making changes to your Python scripts.

2. Next, we need to replace the `if __name__ == '__main__':` block in the `ticker.py` file with the following code. This block of code is the entry point of our script, and by replacing it, we'll be changing how the script processes and displays the data.

```python
if __name__ == '__main__':
    from follow import follow
    import csv
    from tableformat import create_formatter, print_table

    formatter = create_formatter('text')

    lines = follow('stocklog.csv')
    rows = csv.reader(lines)
    records = (Ticker.from_row(row) for row in rows)
    negative = (rec for rec in records if rec.change < 0)
    print_table(negative, ['name', 'price', 'change'], formatter)
```

3. After making these changes, save the file. You can do this by pressing `Ctrl+S` on your keyboard or by selecting "File" â†’ "Save" from the menu. Saving the file ensures that your changes are preserved and can be run later.

## Understanding the Enhanced Pipeline

Let's take a closer look at what this enhanced pipeline does. Understanding each step will help you see how the different parts of the code work together to process and display the data.

1. We start by importing `create_formatter` and `print_table` from the `tableformat` module. This module is already set up for you, and it provides functions that help us format and print the data in a nice table.

2. Then, we create a text formatter using `create_formatter('text')`. This formatter will be used to format the data in a way that's easy to read.

3. Now, let's break down the pipeline step by step:
   - `follow('stocklog.csv')` is a function that generates lines from the `stocklog.csv` file. It continuously monitors the file for new data and provides the lines one by one.
   - `csv.reader(lines)` takes the lines generated by `follow` and parses them into row data. This is necessary because the data in the CSV file is in a text format, and we need to convert it into a structured format that we can work with.
   - `(Ticker.from_row(row) for row in rows)` is a generator expression that converts each row of data into a `Ticker` object. A `Ticker` object represents a stock and contains information such as the stock's name, price, and change.
   - `(rec for rec in records if rec.change < 0)` is another generator expression that filters the `Ticker` objects. It only keeps the objects where the stock's price change is negative. This allows us to focus on the stocks that have decreased in price.
   - `print_table(negative, ['name', 'price', 'change'], formatter)` takes the filtered `Ticker` objects and formats them into a table using the formatter we created earlier. It then prints the table to the console.

This pipeline demonstrates the power of generators. Instead of loading all the data from the file into memory at once, we're chaining together multiple operations (reading, parsing, converting, filtering) and processing the data one item at a time. This saves memory and makes the code more efficient.

## Running the Enhanced Pipeline

Let's run the updated code to see the results.

1. First, make sure you're in the project directory in the terminal. If you're not already there, you can navigate to it using the following command:

   ```bash
   cd /home/labex/project
   ```

2. Once you're in the project directory, run the `ticker.py` script using the following command:

   ```bash
   python3 ticker.py
   ```

3. After running the script, you should see a nicely formatted table in the terminal. This table shows only the stocks with negative price changes.

   ```
          name      price     change
    ---------- ---------- ----------
             C      53.12      -0.21
           UTX      70.04      -0.19
           AXP      62.86      -0.18
           MMM      85.72      -0.22
           MCD      51.38      -0.03
           WMT      49.85      -0.23
            KO       51.6      -0.07
           AIG      71.39      -0.14
            PG      63.05      -0.02
            HD      37.76      -0.19
   ```

If you've seen enough output and want to stop the execution of the script, you can press `Ctrl+C` on your keyboard.

## The Power of Generator Pipelines

What we've created here is a powerful data processing pipeline. Let's summarize what it does:

1. It continuously monitors the `stocklog.csv` file for new data. This means that as new data is added to the file, the pipeline will automatically process it.
2. It parses the CSV data from the file into structured `Ticker` objects. This makes it easier to work with the data and perform operations on it.
3. It filters the data based on a specific criteria, in this case, negative price changes. This allows us to focus on the stocks that are losing value.
4. It formats and presents the filtered data in a readable table. This makes it easy to analyze the data and draw conclusions.

One of the key advantages of using generators in this pipeline is that it uses minimal memory. Generators produce values on-demand, which means they don't store all the data in memory at once. This is similar to Unix pipes, where each component processes the data and passes it on to the next component.

You can think of generators as Lego blocks. Just like you can stack Lego blocks together to create different structures, you can combine generators to create powerful data processing workflows. This modular approach allows you to build complex systems from simple, reusable components.
