{
  "type": "lab",
  "title": "Scaling Large Datasets",
  "description": "This lab focuses on how to scale data analysis to larger datasets using pandas. It covers methods like loading less data, using efficient data types, chunking, and leveraging other libraries like Dask. It is important to note that pandas is more suited for in-memory analytics and might not be the best tool for very large datasets.",
  "meta": {
    "title": "Scaling Large Datasets with Pandas",
    "description": "Learn how to scale data analysis to larger datasets using pandas, including efficient data types, chunking, and leveraging other libraries like Dask.",
    "keywords": "data processing, python playground, pandas, large datasets, python, data scaling, data analysis"
  },
  "difficulty": "Beginner",
  "time": 25,
  "hidden": false,
  "fee_type": "free",
  "show_in_tutorial": true,
  "details": {
    "steps": [
      {
        "title": "Generate Dataset",
        "text": "en/step1.md",
        "verify": [
          {
            "name": "This step has no verification at the moment",
            "file": "verify1-1.sh",
            "hint": "This step has no verification at the moment"
          }
        ],
        "skills": [
          "pandas/conditional_selection",
          "pandas/select_columns",
          "pandas/select_rows",
          "pandas/slicing",
          "python/build_in_functions",
          "python/comments",
          "python/conditional_statements",
          "python/data_analysis",
          "python/default_arguments",
          "python/dictionaries",
          "python/for_loops",
          "python/function_definition",
          "python/importing_modules",
          "python/lambda_functions",
          "python/lists",
          "python/math_random",
          "python/numerical_computing",
          "python/standard_libraries",
          "python/tuples"
        ]
      },
      {
        "title": "Load Less Data",
        "text": "en/step2.md",
        "verify": [
          {
            "name": "This step has no verification at the moment",
            "file": "verify2-1.sh",
            "hint": "This step has no verification at the moment"
          }
        ],
        "skills": [
          "pandas/select_columns",
          "python/comments",
          "python/lists",
          "python/tuples"
        ]
      },
      {
        "title": "Use Efficient Datatypes",
        "text": "en/step3.md",
        "verify": [
          {
            "name": "This step has no verification at the moment",
            "file": "verify3-1.sh",
            "hint": "This step has no verification at the moment"
          }
        ],
        "skills": [
          "pandas/change_data_types",
          "pandas/data_mapping",
          "pandas/select_columns",
          "python/comments",
          "python/for_loops",
          "python/lists",
          "python/numeric_types",
          "python/tuples",
          "python/variables_data_types"
        ]
      },
      {
        "title": "Use Chunking",
        "text": "en/step4.md",
        "verify": [
          {
            "name": "This step has no verification at the moment",
            "file": "verify4-1.sh",
            "hint": "This step has no verification at the moment"
          }
        ],
        "skills": [
          "pandas/change_data_types",
          "pandas/conditional_selection",
          "pandas/select_columns",
          "python/for_loops",
          "python/lists",
          "python/numeric_types",
          "python/standard_libraries",
          "python/variables_data_types"
        ]
      },
      {
        "title": "Use Other Libraries",
        "text": "en/step5.md",
        "verify": [
          {
            "name": "This step has no verification at the moment",
            "file": "verify5-1.sh",
            "hint": "This step has no verification at the moment"
          }
        ],
        "skills": [
          "pandas/select_columns",
          "python/comments",
          "python/importing_modules",
          "python/lists",
          "python/tuples"
        ]
      }
    ],
    "intro": {
      "text": "en/intro.md",
      "background": "setup.sh",
      "title": "Introduction"
    },
    "finish": {
      "text": "en/finish.md",
      "title": "Summary"
    },
    "assets": {
      "host01": [
        {
          "file": "scale.ipynb",
          "target": "/home/labex/project",
          "chmod": "ugo+rwx"
        }
      ]
    }
  },
  "backend": {
    "imageid": "jupyter-ubuntu:2204"
  },
  "contributors": ["huduo0812"],
  "license": {
    "name": "BSD 3-Clause",
    "url": "https://github.com/pandas-dev/pandas/blob/main/LICENSE",
    "repo": "https://github.com/pandas-dev/pandas"
  },
  "i18n": [
    {
      "lang": "zh",
      "title": "扩展大型数据集",
      "description": "本实验重点介绍如何使用pandas将数据分析扩展到更大的数据集。它涵盖了诸如加载更少数据、使用高效数据类型、分块以及利用像Dask这样的其他库等方法。需要注意的是，pandas更适合内存内分析，对于非常大的数据集可能不是最佳工具。",
      "meta": {
        "title": "使用Pandas扩展大型数据集",
        "description": "学习如何使用pandas将数据分析扩展到更大的数据集，包括高效数据类型、分块以及利用像Dask这样的其他库。",
        "keywords": "数据处理, Python实验场, Pandas, 大型数据集, Python, 数据扩展, 数据分析"
      },
      "details": {
        "steps": [
          {
            "title": "生成数据集",
            "text": "zh/step1.md",
            "verify": [
              {
                "name": "此步骤目前没有验证",
                "file": "verify1-1.sh",
                "hint": "此步骤目前没有验证"
              }
            ]
          },
          {
            "title": "加载更少的数据",
            "text": "zh/step2.md",
            "verify": [
              {
                "name": "此步骤目前没有验证",
                "file": "verify2-1.sh",
                "hint": "此步骤目前没有验证"
              }
            ]
          },
          {
            "title": "使用高效的数据类型",
            "text": "zh/step3.md",
            "verify": [
              {
                "name": "此步骤目前没有验证",
                "file": "verify3-1.sh",
                "hint": "此步骤目前没有验证"
              }
            ]
          },
          {
            "title": "使用分块",
            "text": "zh/step4.md",
            "verify": [
              {
                "name": "此步骤目前没有验证",
                "file": "verify4-1.sh",
                "hint": "此步骤目前没有验证"
              }
            ]
          },
          {
            "title": "使用其他库",
            "text": "zh/step5.md",
            "verify": [
              {
                "name": "此步骤目前没有验证",
                "file": "verify5-1.sh",
                "hint": "此步骤目前没有验证"
              }
            ]
          }
        ],
        "intro": {
          "text": "zh/intro.md",
          "title": "介绍"
        },
        "finish": {
          "text": "zh/finish.md",
          "title": "总结"
        }
      }
    },
    {
      "lang": "es",
      "title": "Escalado de Grandes Conjuntos de Datos",
      "description": "Este laboratorio (lab) se centra en cómo escalar el análisis de datos a conjuntos de datos más grandes utilizando pandas. Aborda métodos como cargar menos datos, utilizar tipos de datos eficientes, la división en fragmentos (chunking) y aprovechar otras bibliotecas como Dask. Es importante tener en cuenta que pandas es más adecuado para el análisis en memoria y puede que no sea la mejor herramienta para conjuntos de datos muy grandes.",
      "meta": {
        "title": "Escalado de Grandes Conjuntos de Datos con Pandas",
        "description": "Aprende cómo escalar el análisis de datos a conjuntos de datos más grandes utilizando pandas, incluyendo tipos de datos eficientes, división en fragmentos (chunking) y aprovechamiento de otras bibliotecas como Dask.",
        "keywords": "procesamiento de datos, entorno de prueba de Python, pandas, grandes conjuntos de datos, Python, escalado de datos, análisis de datos"
      },
      "details": {
        "steps": [
          {
            "title": "Generar Conjunto de Datos",
            "text": "es/step1.md",
            "verify": [
              {
                "name": "En este momento, este paso no tiene verificación",
                "file": "verify1-1.sh",
                "hint": "En este momento, este paso no tiene verificación"
              }
            ]
          },
          {
            "title": "Cargar Menos Datos",
            "text": "es/step2.md",
            "verify": [
              {
                "name": "En este momento, este paso no tiene verificación",
                "file": "verify2-1.sh",
                "hint": "En este momento, este paso no tiene verificación"
              }
            ]
          },
          {
            "title": "Utilizar Tipos de Datos Eficientes",
            "text": "es/step3.md",
            "verify": [
              {
                "name": "En este momento, este paso no tiene verificación",
                "file": "verify3-1.sh",
                "hint": "En este momento, este paso no tiene verificación"
              }
            ]
          },
          {
            "title": "Utilizar División en Fragmentos (Chunking)",
            "text": "es/step4.md",
            "verify": [
              {
                "name": "En este momento, este paso no tiene verificación",
                "file": "verify4-1.sh",
                "hint": "En este momento, este paso no tiene verificación"
              }
            ]
          },
          {
            "title": "Utilizar Otras Bibliotecas",
            "text": "es/step5.md",
            "verify": [
              {
                "name": "En este momento, este paso no tiene verificación",
                "file": "verify5-1.sh",
                "hint": "En este momento, este paso no tiene verificación"
              }
            ]
          }
        ],
        "intro": {
          "text": "es/intro.md",
          "title": "Introducción"
        },
        "finish": {
          "text": "es/finish.md",
          "title": "Resumen"
        }
      }
    },
    {
      "lang": "fr",
      "title": "Traitement de grands ensembles de données",
      "description": "Ce laboratoire se concentre sur la manière d'adapter l'analyse de données à des ensembles de données plus volumineux en utilisant pandas. Il couvre des méthodes telles que le chargement de moins de données, l'utilisation de types de données efficaces, le fractionnement (chunking) et l'utilisation d'autres bibliothèques comme Dask. Il est important de noter que pandas est plus adapté aux analyses en mémoire et peut ne pas être l'outil idéal pour de très grands ensembles de données.",
      "meta": {
        "title": "Traitement de grands ensembles de données avec Pandas",
        "description": "Apprenez à adapter l'analyse de données à des ensembles de données plus volumineux en utilisant pandas, y compris l'utilisation de types de données efficaces, le fractionnement (chunking) et l'utilisation d'autres bibliothèques comme Dask.",
        "keywords": "traitement de données, environnement de test Python, pandas, grands ensembles de données, Python, mise à l'échelle des données, analyse de données"
      },
      "details": {
        "steps": [
          {
            "title": "Générer un ensemble de données",
            "text": "fr/step1.md",
            "verify": [
              {
                "name": "Cette étape n'est pas vérifiée pour le moment",
                "file": "verify1-1.sh",
                "hint": "Cette étape n'est pas vérifiée pour le moment"
              }
            ]
          },
          {
            "title": "Charger moins de données",
            "text": "fr/step2.md",
            "verify": [
              {
                "name": "Cette étape n'est pas vérifiée pour le moment",
                "file": "verify2-1.sh",
                "hint": "Cette étape n'est pas vérifiée pour le moment"
              }
            ]
          },
          {
            "title": "Utiliser des types de données efficaces",
            "text": "fr/step3.md",
            "verify": [
              {
                "name": "Cette étape n'est pas vérifiée pour le moment",
                "file": "verify3-1.sh",
                "hint": "Cette étape n'est pas vérifiée pour le moment"
              }
            ]
          },
          {
            "title": "Utiliser le fractionnement (chunking)",
            "text": "fr/step4.md",
            "verify": [
              {
                "name": "Cette étape n'est pas vérifiée pour le moment",
                "file": "verify4-1.sh",
                "hint": "Cette étape n'est pas vérifiée pour le moment"
              }
            ]
          },
          {
            "title": "Utiliser d'autres bibliothèques",
            "text": "fr/step5.md",
            "verify": [
              {
                "name": "Cette étape n'est pas vérifiée pour le moment",
                "file": "verify5-1.sh",
                "hint": "Cette étape n'est pas vérifiée pour le moment"
              }
            ]
          }
        ],
        "intro": {
          "text": "fr/intro.md",
          "title": "Introduction"
        },
        "finish": {
          "text": "fr/finish.md",
          "title": "Résumé"
        }
      }
    },
    {
      "lang": "de",
      "title": "Skalierung großer Datensätze",
      "description": "Dieses Lab konzentriert sich darauf, wie man Datenanalysen auf größere Datensätze skalieren kann, indem man pandas verwendet. Es behandelt Methoden wie das Laden weniger Daten, die Verwendung effizienter Datentypen, Chunking (Teilen von Daten) und die Nutzung anderer Bibliotheken wie Dask. Es ist wichtig zu beachten, dass pandas eher für In-Memory-Analysen geeignet ist und möglicherweise nicht das beste Werkzeug für sehr große Datensätze ist.",
      "meta": {
        "title": "Skalierung großer Datensätze mit Pandas",
        "description": "Lernen Sie, wie Sie Datenanalysen auf größere Datensätze skalieren können, indem Sie pandas verwenden, einschließlich effizienter Datentypen, Chunking und die Nutzung anderer Bibliotheken wie Dask.",
        "keywords": "Datenverarbeitung, Python-Playground, pandas, große Datensätze, Python, Daten-Skalierung, Datenanalyse"
      },
      "details": {
        "steps": [
          {
            "title": "Datensatz generieren",
            "text": "de/step1.md",
            "verify": [
              {
                "name": "Dieser Schritt hat derzeit keine Überprüfung",
                "file": "verify1-1.sh",
                "hint": "Dieser Schritt hat derzeit keine Überprüfung"
              }
            ]
          },
          {
            "title": "Weniger Daten laden",
            "text": "de/step2.md",
            "verify": [
              {
                "name": "Dieser Schritt hat derzeit keine Überprüfung",
                "file": "verify2-1.sh",
                "hint": "Dieser Schritt hat derzeit keine Überprüfung"
              }
            ]
          },
          {
            "title": "Effiziente Datentypen verwenden",
            "text": "de/step3.md",
            "verify": [
              {
                "name": "Dieser Schritt hat derzeit keine Überprüfung",
                "file": "verify3-1.sh",
                "hint": "Dieser Schritt hat derzeit keine Überprüfung"
              }
            ]
          },
          {
            "title": "Chunking verwenden",
            "text": "de/step4.md",
            "verify": [
              {
                "name": "Dieser Schritt hat derzeit keine Überprüfung",
                "file": "verify4-1.sh",
                "hint": "Dieser Schritt hat derzeit keine Überprüfung"
              }
            ]
          },
          {
            "title": "Andere Bibliotheken verwenden",
            "text": "de/step5.md",
            "verify": [
              {
                "name": "Dieser Schritt hat derzeit keine Überprüfung",
                "file": "verify5-1.sh",
                "hint": "Dieser Schritt hat derzeit keine Überprüfung"
              }
            ]
          }
        ],
        "intro": {
          "text": "de/intro.md",
          "title": "Einführung"
        },
        "finish": {
          "text": "de/finish.md",
          "title": "Zusammenfassung"
        }
      }
    },
    {
      "lang": "ja",
      "title": "大規模データセットの拡張",
      "description": "この実験では、pandas を使用してデータ分析を大規模なデータセットに拡張する方法に焦点を当てています。必要なデータのみを読み込む方法、効率的なデータ型を使用する方法、チャンク分割を行う方法、および Dask のような他のライブラリを活用する方法などがカバーされています。pandas はメモリ内分析に適しており、非常に大きなデータセットには必ずしも最適なツールではないことに注意する必要があります。",
      "meta": {
        "title": "Pandas で大規模データセットを拡張する",
        "description": "pandas を使用してデータ分析を大規模なデータセットに拡張する方法を学びましょう。効率的なデータ型、チャンク分割、および Dask のような他のライブラリの活用方法が含まれます。",
        "keywords": "データ処理, Python プレイグラウンド, pandas, 大規模データセット, Python, データ拡張, データ分析"
      },
      "details": {
        "steps": [
          {
            "title": "データセットを生成する",
            "text": "ja/step1.md",
            "verify": [
              {
                "name": "現時点でこのステップの検証はありません",
                "file": "verify1-1.sh",
                "hint": "現時点でこのステップの検証はありません"
              }
            ]
          },
          {
            "title": "必要最小限のデータを読み込む",
            "text": "ja/step2.md",
            "verify": [
              {
                "name": "現時点でこのステップの検証はありません",
                "file": "verify2-1.sh",
                "hint": "現時点でこのステップの検証はありません"
              }
            ]
          },
          {
            "title": "効率的なデータ型を使用する",
            "text": "ja/step3.md",
            "verify": [
              {
                "name": "現時点でこのステップの検証はありません",
                "file": "verify3-1.sh",
                "hint": "現時点でこのステップの検証はありません"
              }
            ]
          },
          {
            "title": "チャンク分割を使用する",
            "text": "ja/step4.md",
            "verify": [
              {
                "name": "現時点でこのステップの検証はありません",
                "file": "verify4-1.sh",
                "hint": "現時点でこのステップの検証はありません"
              }
            ]
          },
          {
            "title": "他のライブラリを使用する",
            "text": "ja/step5.md",
            "verify": [
              {
                "name": "現時点でこのステップの検証はありません",
                "file": "verify5-1.sh",
                "hint": "現時点でこのステップの検証はありません"
              }
            ]
          }
        ],
        "intro": {
          "text": "ja/intro.md",
          "title": "はじめに"
        },
        "finish": {
          "text": "ja/finish.md",
          "title": "まとめ"
        }
      }
    },
    {
      "lang": "ru",
      "title": "Масштабирование больших наборов данных",
      "description": "В этом практическом занятии (lab) основное внимание уделяется тому, как масштабировать анализ данных для работы с большими наборами данных с использованием pandas. Здесь рассматриваются методы, такие как загрузка меньшего количества данных, использование эффективных типов данных, разбиение на части (chunking) и применение других библиотек, таких как Dask. Важно отметить, что pandas лучше всего подходит для аналитики данных, которые помещаются в память, и может не быть наилучшим инструментом для работы с очень большими наборами данных.",
      "meta": {
        "title": "Масштабирование больших наборов данных с использованием pandas",
        "description": "Узнайте, как масштабировать анализ данных для работы с большими наборами данных с использованием pandas, включая применение эффективных типов данных, разбиение на части (chunking) и использование других библиотек, таких как Dask.",
        "keywords": "обработка данных, Python-песочница, pandas, большие наборы данных, Python, масштабирование данных, анализ данных"
      },
      "details": {
        "steps": [
          {
            "title": "Создание набора данных",
            "text": "ru/step1.md",
            "verify": [
              {
                "name": "На данный момент эта стадия не имеет проверки",
                "file": "verify1-1.sh",
                "hint": "На данный момент эта стадия не имеет проверки"
              }
            ]
          },
          {
            "title": "Загрузка меньшего объема данных",
            "text": "ru/step2.md",
            "verify": [
              {
                "name": "На данный момент эта стадия не имеет проверки",
                "file": "verify2-1.sh",
                "hint": "На данный момент эта стадия не имеет проверки"
              }
            ]
          },
          {
            "title": "Использование эффективных типов данных",
            "text": "ru/step3.md",
            "verify": [
              {
                "name": "На данный момент эта стадия не имеет проверки",
                "file": "verify3-1.sh",
                "hint": "На данный момент эта стадия не имеет проверки"
              }
            ]
          },
          {
            "title": "Использование разбиения на части (chunking)",
            "text": "ru/step4.md",
            "verify": [
              {
                "name": "На данный момент эта стадия не имеет проверки",
                "file": "verify4-1.sh",
                "hint": "На данный момент эта стадия не имеет проверки"
              }
            ]
          },
          {
            "title": "Использование других библиотек",
            "text": "ru/step5.md",
            "verify": [
              {
                "name": "На данный момент эта стадия не имеет проверки",
                "file": "verify5-1.sh",
                "hint": "На данный момент эта стадия не имеет проверки"
              }
            ]
          }
        ],
        "intro": {
          "text": "ru/intro.md",
          "title": "Введение"
        },
        "finish": {
          "text": "ru/finish.md",
          "title": "Резюме"
        }
      }
    }
  ]
}
